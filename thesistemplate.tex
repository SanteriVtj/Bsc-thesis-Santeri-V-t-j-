%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                                                %%
%% An example for writting your thesis using LaTeX                %%
%% Original version by Luis Costa,  changes by Perttu Puska       %%
%% Support for Swedish added 15092014                             %%
%%                                                                %%
%% This example consists of the files                             %%
%%         thesistemplate.tex (versio 2.01)                       %%
%%         opinnaytepohja.tex (versio 2.01) (for text in Finnish) %%
%%         aaltothesis.cls (versio 2.01)                          %%
%%         kuva1.eps                                              %%
%%         kuva2.eps                                              %%
%%         kuva1.pdf                                              %%
%%         kuva2.pdf                                              %%
%%                                                                %%
%%                                                                %%
%% Typeset either with                                            %%
%% latex:                                                         %%
%%             $ latex opinnaytepohja                             %%
%%             $ latex opinnaytepohja                             %%
%%                                                                %%
%%   Result is the file opinnayte.dvi, which                      %%
%%   is converted to ps format as follows:                        %%
%%                                                                %%
%%             $ dvips opinnaytepohja -o                          %%
%%                                                                %%
%%   and then to pdf as follows:                                  %%
%%                                                                %%
%%             $ ps2pdf opinnaytepohja.ps                         %%
%%                                                                %%
%% Or                                                             %%
%% pdflatex:                                                      %%
%%             $ pdflatex opinnaytepohja                          %%
%%             $ pdflatex opinnaytepohja                          %%
%%                                                                %%
%%   Result is the file opinnaytepohja.pdf                        %%
%%                                                                %%
%% Explanatory comments in this example begin with                %%
%% the characters %%, and changes that the user can make          %%
%% with the character %                                           %%
%%                                                                %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%% Uncomment one of these:
%% the 1st when using pdflatex, which directly typesets your document in
%% pdf (use jpg or pdf figures), or
%% the 2nd when producing a ps file (use eps figures, don't use ps figures!).
\documentclass[main=english,12pt,a4paper,pdftex,econ,utf8]{aaltothesis}
\usepackage{comment}
\usepackage{caption}
\usepackage{capt-of}
\usepackage{libertine}
\usepackage{adjustbox}
%\documentclass[english,12pt,a4paper,dvips]{aaltothesis}

%% To the \documentclass above
%% specify your school: arts, biz, chem, elec, eng, sci, econ
%% specify the character encoding scheme used by your editor: utf8, latin1

%% Use one of these if you write in Finnish (see the Finnish template):
%%
%\documentclass[finnish,12pt,a4paper,pdftex,elec,utf8]{aaltothesis}
%\documentclass[finnish,12pt,a4paper,dvips]{aaltothesis}

\usepackage{graphicx}

%% Use this if you write hard core mathematics, these are usually needed
\usepackage{amsfonts,amssymb,amsbsy,amsmath,bm}
\usepackage{color, soul}
\usepackage{pst-node, auto-pst-pdf}
\usepackage{caption}
\captionsetup{labelfont={bf}}
%% Use the macros in this package to change how the hyperref package below 
%% typesets its hypertext -- hyperlink colour, font, etc. See the package
%% documentation. It also defines the \url macro, so use the package when 
%% not using the hyperref package.
%%
%\usepackage{url}

%% Use this if you want to get links and nice output. Works well with pdflatex.
\usepackage{tikz}
\usepackage{verbatim}
\usepackage{forest}
\usepackage{etoolbox}
\usepackage{multirow}
\usepackage{adjustbox}
\usetikzlibrary{arrows,trees,positioning}
\tikzstyle{circleobject}=[circle,fill=white,draw,line width=0.5mm]
\tikzstyle{line}=[draw]
\tikzstyle{arrow}=[draw, -latex]
\usetikzlibrary{arrows.meta}


\tikzset{%
    /forest,
    forest node/.style={circle, inner sep=0pt, text centered},
    arn n/.append style={text=white, font=\sffamily\bfseries, draw=black, text width=1.5em},
    arn r/.append style={text=red, draw=red, text width=1.5em, very thick},
  }
\usepackage{hyperref}
\usepackage{csquotes}
\usepackage{enumerate}
\usepackage{newtxtext,newtxmath}
\hypersetup{
    pdfpagemode=UseNone, 
    colorlinks=true,
    filecolor=blue,
    pdfstartview=FitH,
    urlcolor=blue,
    linkcolor=red,
    citecolor=black,
    pdftitle={Default Title, Modify},
    pdfauthor={Your Name},
    pdfkeywords={Modify keywords},
    urlcolor=blue
}

\usepackage[
    backend=biber,
    sorting=nyt,
    style=authoryear,
    citestyle=apa
]{biblatex}
\addbibresource{library.bib}
\addbibresource{manual.bib}
\linespread{1.5}
%----------------- NEW COMMANDS -----------------
\newcommand{\indep}{\perp \!\!\! \perp}
\newcommand{\nindep}{\not\!\indep}
\newcommand{\dsep}{\stackrel{d}{\indep}}
\let\emptyset\varnothing
\newcommand{\ch}[1]{Ch(#1)}
\newcommand{\pa}[1]{Pa(#1)}
\newcommand{\de}[1]{De(#1)}
\newcommand{\z}{\mathcal{Z}}
\newcommand{\g}{\mathcal{G}}
\newcommand{\e}{\bm{\epsilon}}
\newcommand{\vars}{\bm{V}}
\newcommand{\unobs}{\bm{U}}
\newcommand{\wrap}[1]{\parbox{.33\linewidth}{\vspace{1.5mm}#1\vspace{1mm}}}
\DeclareCaptionType{lcaption}[List][List of things]
%------------------------------------------------
%% All that is printed on paper starts here
\begin{document}

%% Change the school field to specify your school if the automatically 
%% set name is wrong
% \university{aalto-yliopisto}
% \university{aalto University}
% \school{Sähkötekniikan korkeakoulu}
% \school{School of Electrical Engineering}

%% Only for B.Sc. thesis: Choose your degree programme. 
\degreeprogram{Bachelor's Programme in Economics}
%%

%% ONLY FOR M.Sc. AND LICENTIATE THESIS: Specify your department,
%% professorship and professorship code. 
%%
\department{Department of Economics}
%\professorship{Circuit theory}
%%

%% Valitse yksi näistä kolmesta
%%
%% Choose one of these:
\univdegree{BSc}
%\univdegree{MSc}
%\univdegree{Lic}



%% Your own name (should be self explanatory...)
\author{Santeri Väätäjä}

%% Your thesis title comes here and again before a possible abstract in
%% Finnish or Swedish . If the title is very long and latex does an
%% unsatisfactory job of breaking the lines, you will have to force a
%% linebreak with the \\ control character. 
%% Do not hyphenate titles.
%% 
\thesistitle{\mbox{Directed acyclic graph causal inference framework} and its applications in econometrics}

\place{Espoo}

%% For B.Sc. thesis use the date when you present your thesis. 
%% 
%% Kandidaatintyön päivämäärä on sen esityspäivämäärä! 
\date{24.8.2021}

%% B.Sc. or M.Sc. thesis supervisor 
%% Note the "\" after the comma. This forces the following space to be 
%% a normal interword space, not the space that starts a new sentence. 
%% This is done because the fullstop isn't the end of the sentence that
%% should be followed by a slightly longer space but is to be followed
%% by a regular space.
%%
\supervisor{Prof. Pauli Murto} %{Prof.\ Pirjo Professori}

%% B.Sc. or M.Sc. thesis advisors(s). You can give upto two advisors in
%% this template. Check with your supervisor how many official advisors
%% you can have.
%%
%\advisor{Prof.\ Pirjo Professori}
\advisor{Asst. Prof. Ciprian Domnisoru}
%\advisor{M.Sc.\ Polli Pohjaaja}

%% Aalto logo: syntax:
%% \uselogo{aaltoRed|aaltoBlue|aaltoYellow|aaltoGray|aaltoGrayScale}{?|!|''}
%%
%% Logo language is set to be the same as the document language.
%% Logon kieli on sama kuin dokumentin kieli
%%
\uselogo{aaltoRed}{''}

%% Create the coverpage
%%
\makecoverpage


%% Note that when writting your master's thesis in English, place
%% the English abstract first followed by the possible Finnish abstract

%% English abstract.
%% All the information required in the abstract (your name, thesis title, etc.)
%% is used as specified above.
%% Specify keywords
%%
%% Kaikki tiivistelmässä tarvittava tieto (nimesi, työnnimi, jne.) käytetään
%% niin kuin se on yllä määritelty.
%% Avainsanat
%%
\keywords{directed acyclic graphs, causal inference, nonparametric methods}
%% Abstract text
\begin{abstractpage}[english]
This thesis aims to first provide review of causal inference within directed acyclic graph models and then try to apply this knowledge on how it might be affecting the applicability of model in econometric context. First part is going through theoretical literature on graphs and statistical graphical models. Selected model to which closer look is taken will be graphical model developed largely by Judea Pearl with its identification machinery. However some different approaches are also contrasted to chosen approach.

Second part is using the theory to show some specific problems considering the framework and taking a look at pre-existing literature in economics regarding this kind of model. Finally some benefits and possibilities currently as well as in future and some possible developments and their effects for possibilities in economics are discussed. This part concludes that graphs are having unique features that would enable easier and more cost efficient use. However to really be useful problems such as function restrictions and enabling equilibrium condition needs to be solved.
\begin{comment}
Your abstract in English. Try to keep the abstract short; approximately 
100 words should be enough. The abstract explains your research topic, 
the methods you have used, and the results you obtained.  
Your abstract in English. Try to keep the abstract short; approximately 
100 words should be enough. The abstract explains your research topic, 
the methods you have used, and the results you obtained.  

Your abstract in English. Try to keep the abstract short; approximately 
100 words should be enough. The abstract explains your research topic, 
the methods you have used, and the results you obtained.  
Your abstract in English. Try to keep the abstract short; approximately 
100 words should be enough. The abstract explains your research topic, 
the methods you have used, and the results you obtained.  
\end{comment}    
\end{abstractpage}

%% Force a new page so that the possible English abstract starts on a new page
%%
%% Pakotetaan uusi sivu varmuuden vuoksi, jotta 
%% mahdollinen suomenkielinen ja englanninkielinen tiivistelmä
%% eivät tule vahingossakaan samalle sivulle
\begin{comment}
\newpage
%
%% Abstract in Finnish.  Delete if you don't need it. 
\thesistitle{Opinnäyteohje}
\advisor{TkT Olli Ohjaaja}
\degreeprogram{Electronics and electrical engineering}
\department{Radiotieteen ja -tekniikan laitos}
\professorship{Piiriteoria}
%% Avainsanat
\keywords{Vastus, Resistanssi,\\ Lämpötila}
%% Tiivistelmän tekstiosa
\begin{abstractpage}[finnish]
  Tiivistelmässä on lyhyt selvitys (noin 100 sanaa)
  kirjoituksen tärkeimmästä sisällöstä: mitä ja miten on tutkittu,
  sekä mitä tuloksia on saatu. 
  Tiivistelmässä on lyhyt selvitys (noin 100 sanaa)
  kirjoituksen tärkeimmästä sisällöstä: mitä ja miten on tutkittu,
  sekä mitä tuloksia on saatu. 

  Tiivistelmässä on lyhyt selvitys (noin 100 sanaa)
  kirjoituksen tärkeimmästä sisällöstä: mitä ja miten on tutkittu,
  sekä mitä tuloksia on saatu. 
  Tiivistelmässä on lyhyt selvitys (noin 100 sanaa)
  kirjoituksen tärkeimmästä sisällöstä: mitä ja miten on tutkittu,
  sekä mitä tuloksia on saatu. 
  Tiivistelmässä on lyhyt selvitys (noin 100 sanaa)
  kirjoituksen tärkeimmästä sisällöstä: mitä ja miten on tutkittu,
  sekä mitä tuloksia on saatu. 
\end{abstractpage}

\end{comment}
%% Force new page so that the Swedish abstract starts from a new page
\newpage
%
%% Swedish abstract. Delete if you don't need it. 
%% 

%% Table of contents.
{
\hypersetup{linkcolor=black}
\thesistableofcontents
}

%% Symbols and abbreviations
\mysection{Symbols and abbreviations}

\subsection*{Symbols}

\begin{tabular}{ll}
$\vars$ & set of vertices $\{V_{1},V_{2},\ldots,V_{N}\}$ \\
$\unobs$ & set of unobserved/exogenous variables $\{U_{1},U_{2},\ldots,U_{N}\}$ \\
$\e$ & set of edges $\{\epsilon_{1},\epsilon_{2},\ldots,\epsilon_{N}\}$ \\
$\emptyset$ & graph with no nodes or vertices \\
$\g$ & graph \\
$\z$ & subset of variables within graph
\end{tabular}

\subsection*{Operators}

\begin{tabular}{ll}
$\indep$ & independent \\
$\nindep$ & not independent \\
%$\dsep$ & d-separation \\
$\pa{\bm{\cdot}}$ & parents of given node \\
$\ch{\bm{\cdot}}$ & children of given node \\
$\de{\bm{\cdot}}$ & descendants of given node \\
$Pr(\bm{\cdot})$ & probability
\begin{comment}
$\nabla \times \mathbf{A}$              & curl of vectorin $\mathbf{A}$\\
$\displaystyle\frac{\mbox{d}}{\mbox{d} t}$ & derivative with respect to 
variable $t$\\[3mm]
$\displaystyle\frac{\partial}{\partial t}$  & partial derivative with respect 
to variable $t$ \\[3mm]
$\sum_i $                       & sum over index $i$\\
$\mathbf{A} \cdot \mathbf{B}$    & dot product of vectors $\mathbf{A}$ and 
$\mathbf{B}$
\end{comment}
\end{tabular}

\subsection*{Abbreviations}
\begin{tabular}{ll}
DAG & directed acyclic graph \\
DCG & directed cyclic graph \\
SEM & structural equation model \\
LMC & local Markov condition \\
IV  & intrumental variable
\end{tabular}


%% Tweaks the page numbering to meet the requirement of the thesis format:
%% Begin the pagenumbering in Arabian numerals (and leave the first page
%% of the text body empty, see \thispagestyle{empty} below).
%% Additionally, force the actual text to begin on a new page with the 
%% \clearpage command.
%% \clearpage is similar to \newpage, but it also flushes the floats (figures
%% and tables).
%% There is no need to change these
%%
\cleardoublepage
\storeinipagenumber
\pagenumbering{arabic}
\setcounter{page}{1}


%% Text body begins. Note that since the text body
%% is mostly in Finnish the majority of comments are
%% also in Finnish after this point. There is no point in explaining
%% Finnish-language specific thesis conventions in English. Someday 
%% this text will possibly be translated to English.
%%
%\section{Introduction}

%% Ensimm\"ainen sivu tyhj\"aksi
%% 
%% Leave first page empty
%\thispagestyle{empty}
%\clearpage

\section{Introduction}

Declaring causal inference has been for a long time debated area, in social sciences in general, and respectively in economics. It is naturally very interesting for scientists across the fields to establish more profound connections than correlation to events affecting their studies. It also works as a way for economists to have larger effect on society as it enables policy advises to have more solid foundation on the effects of particular policy changes studied and research to identify relations of the particular events that can be interpreted as causal.

This thesis is meant to give an overview on a one of such a methods that can be used to infer causal connections from data. Method discussed in this thesis, directed acyclic graph (DAG) causal inference, is a method used in multiple fields like computer science and epidemiology, but have had smaller role in social sciences. However in recent years there has been more interest also from these fields and one of the main advocates of this method, a computer scientist who have done research on this method, Judea Pear is arguing that DAG methods should be used also in economics (\cite{pearl_2014}) and having discussions with economists such as Guido Imbens over articles (\cite{Imbens2014}; \cite{imbes2020}) and James Hekcman and Rodrigo Pinto (\cite{Heckman2015}) about the suitability of the framework in economics.

First content section \ref{section:overview} of this thesis tries to explain most essential concepts of graph theory that are prerequisites for understanding the statistical interpretation. This part is mainly based Pearls older paper going through the fundamentals of this method (\cite{Pearl1998}) and textbook about causal inference (\cite{Peters2017}).

Second section \ref{section:stats and ci} builds on top of the first and starts to give statistical properties for graphs and goes through some of the causal inference tools used with graphs. Properties of model and methods introduced here are needed later on to understand why some specific parts of the model or tool set associated with it are either useful or causing troubles in econometric applications. Again lot of the articles gone through and with which certain properties for model are defined are produced by Pearl and his coauthors. Two important topic here, developed partly by Pear, are \textit{do-calculus} and \textit{identification methods} and literary considering these will contains multiple articles by him for definitions for these tools. In addition for that some contrasts are made with alternative choices that might be used like hypothetical graphs by Heckman (\cite{Heckman2015}) which introduces a bit differing way to use graphs in causal inference applications.

Last section (\ref{section:economics}) is solely dedicated for finding out the economics perspective. At the beginning some of the existing empiric papers using at least in some form DAGs are introduced. These are macro economics articles considering Granger causality and thus not using identification strategies offered by DAGs. This is also one of the problems on this thesis that there isn't much empirical economic research that would be done with DAGs. Thus also much of this thesis is centered more towards the possible benefits and shortcomings which are gone through more systematically in sections \ref{subsection:problems} \& \ref{subsection:benefits}. These parts are mostly taking a look at some newer research and working papers considering some of the still existing problems for economics such as implementation of equilibrium condition and instrument variables.

With the last sections I am trying to find out how this model relates to some of those already existing ways. There also some of the properties of model that would benefit economic research especially in policy settings and features that might make it much cheaper to conduct research in some specific cases compared to randomized controlled trials. These are due to possibility to handle selection and transport the model to different locations without necessarily estimating it again from the beginning introduced there.

\clearpage

\section{Overview of directed acyclic graphs} \label{section:overview}

This section will take a look of general structure of graphs as well as what kind of notations are used with graphs in general and with statistical interpretation. First the basics of graphs as structure and terms used as a basis for the statistical interpretations are gone through. This should provide necessary concepts needed to understand the framework as well as at later stage help understand the features either causing problems when DAGs are used in economic settings or features that might benefit economic analysis.

Secondly the operators used to define further properties that make graphs useful in statistical applications are introduced. These properties are very generally applicable for graphs also outside the causal inference framework and can be given for graphs as a general mathematical objects. However the implications of those are highly important for further discussion and to understand the building blocks of the statistical model as well as defining features such as independence in model.

\subsection{Directed acyclic graph as structure}

DAGs are at simplest just set containing variables $\vars$ that have some extra restrictions regarding the way variables, or nodes in graph context, are connected withing the graph. Variables in $\vars$ themselves does not have many restrictions. Graphs in this use should not be mixed with another meaning of word in mathematics. Graph showing for example picture of some function on x and y-axis is entirely different thing.

Aforementioned restrictions for DAGs are defining the set of possible relations for variables in the graph in hand as well as defining not permitted structures in the topological paths. Paths build up from the edges contained in $\e$ which contains the relational information of graph. Edges thus have in DAGs property of direction and information where edge begins and where it ends. Edges and directions of a graph are not symmetric relations in case of DAGs since $\e\subseteq \{\vars^2\setminus(i,i)\}$ where $\epsilon_i=(i,j)\neq(j,i)$ which is necessary but not sufficient condition for acyclicity. When the graph is directed it leads to the topological ordering necessarily being proceeding at every point and never having an edge leading backwards in topological order as figure \ref{fig:topological} shows (\cite{Peters2017}).

\input{topological_ordering}

In this thesis specially directed and acyclic graphs are discussed and thus edges have the direction information or the information of in which direction each edge can be travelled. Acyclicity means that one node cannot exist twice in any possible path. In case node would exist twice in path it could appear infinitely many times in path due to the nature of cycles. This radically reduces the number of algorithms and methods that can be applied to the graph as well as the assumptions that can be made in the context of the graph allowing statistical interpretations. Breaking acyclicity also prevents use of the causal inference methods in similar form presented in this thesis. If there would exist cycles graph becomes directed cyclical graph and DCGs are fundamentally non recursive structures. This breaks some of the relationships that DAGs have, and which will be discussed in more detail and in economic context in section \ref{section:economics} (\cite{Heckman2015}). In other words, cyclicity introduces feedback mechanism for the structure which would lead to the graph being recursive and variables would therefore have causal effect with themselves. This is making the handling of model much harder, and methods introduced for directed acyclic graphs are not many times applicable in these cases at least without some modification or generalization of those. Theory for these different structures is not discussed in this thesis in depth, but some of the properties for those models are discussed in section \ref{section:economics} due to their high significance or possible significance for economic applications.

\subsection{Graph operators}

As graphs have additional conditions defined compared to normal set of objects there also exists operators that graphs have specially defined for them. These operators are also necessary for the causal analysis as these give tools for analyze and define parts of graph and differentiate subgraphs with specific features from the rest.

First concept to know is a path. Path in directed graph consists of variables that have consecutive edges connecting them so that for every variable in path, $V_{i}\rightarrow V_{i+1}$ holds. These of course also have role in causal inference as they describe the routes that causal relationships are influencing other variables. Also tightly connected to paths are the colliders, which always exists in relation to paths. Collider in path is structure where aforementioned condition does not hold but there exist directed edge so $V_{i}\rightarrow V_{i-1}$. Example of such can be seen in figure \ref{fig:topological} DAG where path from $V_{1}$ to $V_{3}$ has subgraph $V_{1}\rightarrow V_{3}$ where no collider exist. Two of the other paths clearly have colliders as $V_{1}\rightarrow V_{2}\rightarrow V_{4}\rightarrow V_{5}\leftarrow V_{3}$ has $V_{5}$ forming collider and $V_{1}\rightarrow V_{2}\rightarrow V_{4}\leftarrow V_{3}$ has $V_{4}$ as collider node.

Path such as $V_{2}\leftarrow V_{1}\rightarrow V_{3}$ in figure \ref{fig:topological} are still further called fork. In fork middle node has two edges emerging from it. Path such as $V_{1}\rightarrow V_{3}\rightarrow V_{5}$ are called chains and in this type of path all edges are parallel.

With paths it is possible define further relations, usually called kinship, for nodes or subgraphs. These operators are also needed to analyze causal structure in graphs since those enable distinguishing independence in graph and thus to define the statistical estimates for causality. Ancestor of variable $V_{i}$ in directed graph, is such other variable appearing before $V_{i}$ in topological order that has direct path to $V_{i}$. If node is appearing only one edge before $V_{i}$ it is called parent node and set of parents is denoted as $\pa{\bm{\cdot}}$. Respectively if there is direct path from $V_{i}$ to some other node it is called its descendant and set of descendants is denoted by $\de{\bm{\cdot}}$. If there is path from $V_{i}$, only one edge long, node is called children $\ch{\bm{\cdot}}$.

\clearpage

\section{Directed acyclical graphs for statistics and causal inference} \label{section:stats and ci}

Graphs needs or at least most of the time are used with, some special mathematical machinery when those are applied for causal inference. This section will take an overview to statistical applications of graphs and especially Markovian or causal graphs by going through some of the most fundamental tools to understand for causal inference in graphical models on conceptual level.

First part will be defining the way DAGs bring together necessary conditions for conditional independence and provides one of the most crucial concepts for the probabilistic interpretation, local Markov condition. With d-separation it is possible to isolate the necessary variables by conditioning the right set of variables and with the combination of these two we can start to make statistical sense within graphs.

With the help of local Markov condition, we can now factorize conditional probabilities out of the set of variables by conditioning the correct set of variables. For the first time everything talked about the general structure, operators and methods will come together and make it possible for the graph to make sense in statistical sense. At this point it gets possible to define the model within which the causal analysis is going to operate.

Third part then introduces the ways to identify causal effects between variables and few of the most common strategies for that. In addition, do-calculus which is distinguishing DAGs from other causal frameworks and having its impact on the popularity of the model. This part will cover the mathematical machinery and the rules associated with it after which main components of the DAG framework in its simplest form is covered.

\subsection{D-separation and independence} \label{subsection:d and indep}

D-separation and independence are closely related concepts and in part overlapping. D-separation is only used in context of graphical models and implies independence between two variables within graph. Variables can be independent in graph by two ways. First one is if only connecting paths are colliders. That leads two variables being independent without any further action or conditioning. Second way to establish d-separation is to have ordered pair of variables $(X, Y)$ be separated from each other by set of variables $\z$. Set of variables $\z$ however have few extra conditions for the variables it is containing:

\begin{enumerate}
    \item Variables in $\z$ are in path between variables $X$ and $Y$ in paths that are either chains or forks. This would correspond controlling $\{V_{2},V_{3}\}$ or $\{V_{2},V_{4}\}$ in figure \ref{fig:topological} if the exposure variable is $V_{1}$ and outcome variable $V_{5}$.
    \item Variables of $\z$ are not variables or descendants of variables that construct collider on path.
\end{enumerate}

From above can be seen there can exist multiple efficient\footnote{Set containing minimum amount of variables that fulfills the conditions for d-separation.} subsets of $\z$ even though also conditioning all other variables than colliders or their descendants would also lead to proper d-separation (\cite{Pearl2016}). These rules are also illustrated by table \ref{tab:independence}. However choosing good set of variable to control instead of all of $\z$ can also be utilized in situation where for example measuring some variable would be harder than others. Further, d-separation can help us make testable hypotheses that are implied by the graphical model. This is something setting graphical models apart from other types of causal inference methods by its very mechanical character and also key part in enabling causal claims from observational data.

\input{independence table}

To have independence with these conditions, model should also be Markovian and fulfill local Markov condition (LMC). Model is considered Markovian when all of the unobservable variables or residuals are jointly independent and the model is acyclic. However sometimes some of those unobservables variables are showed in graph and if we know which variables it is effecting i.e. which variables are having some jointly dependent unobservable variables. By including unobservables making variables jointly dependent, it is still possible to work with it. For the causal claim to be testable some extra requirements need to be taken care of while choosing $\z$ as those unobservables open up new paths that need to be conditioned or in case of collider not conditioned. These kind of models are called semi-Markovian.

Local Markov condition on the other hand is the condition that is needed to provide the independecy by d-separation and thus also translate the graphical properties of a graph to causal claim (\cite{Heckman2015}). LMC is telling us that the variables are independent of other ancestors they have, conditional on their parents. Equation \ref{eq:lmc} is saying that all $v_i$ in $\vars$ are independent of the set of variables containing its other ancestors than parent if conditioned with its parent. Formally defined LMC is:

\begin{gather} \label{eq:lmc}
    \forall v_{i}\in\vars\text{: }v_{i}\indep\vars\setminus\{\de{v_{i}}\cup \{v_{i}\}\}\,|\,\pa{v_{i}}
\end{gather}

Now with the LMC condition and graphoid statements that are defining the independence conditions that were found out to hold in undirected graphs (\cite{Paz1985}) and later also in directed (\cite{Pearl1986}). These needs to be met to have conditional independence and it gets possible to attach statistical relevance for graphs.

\subsection{Statistical interpretation of directed acyclical graphs}

From LMC (\ref{eq:lmc}) it is finally possible to derive the general factorization of variables in graphs. As the LMC suggests the parents of node are somewhat special group in context of the probabilistic interpretation by saying that other ancestors than parents are in fact irrelevant for the factorizing of probability distribution for variable. This is same as with any probability calculation but as mentioned in section \ref{subsection:d and indep} it is also found to be applicable for graphs. Joint distribution for variables $Pr(V_1,V_2,\ldots,V_n)$ in recursive model can be derived from LMC (\ref{eq:lmc}). With $|\vars|=N$ variables that are ordered as $V_1,V_2,\ldots,V_{n-1}$ not being descendants of $V_n$ and $V_{n+1},\ldots,V_{N}$ being descendants of the same variable $V_n$, implying $\pa{V_n}\subseteq V_1,V_2,\ldots,V_{n-1}$ (\cite{Heckman2015}). With this and assumption regarding exogenous variables $\unobs$ to be jointly independent, it is possible to show conditional independence being:

\begin{align} \label{eq:factor}
    \begin{split}
        Pr(V_1,V_2,\ldots,V_{n})&=\prod_{V_{n}\in\vars}Pr(V_{n}|V_1,V_2,\ldots,V_{n-1}) \\
        &=\prod_{V_{n}\in\vars}Pr(V_{n}|\pa{V_{n}})
    \end{split}
\end{align}

\noindent With factorization defined it gets possible to give some meaningful causal interpretation properties for graphs as probability is now meaningful concept in context of graph.

To start making sense of the model with data and having causal interpretation for the relations of functions between nodes those need to be defined. There have been and is multiple different approaches for this. One of the first approaches was to write SEM with linear equations like $y=\beta x+u$ and then give the causal relation in graph based on the theoretical or observed knowledge of situation (\cite{Wright1921}). This can however be generalized also to non-parametric functions which is for now on thought to be the default model here. SEM is constructed so that it contains functions for all observed variables (\cite{Pearl2008}), however in model of figure \ref{fig:npmodel} each function contains all of the unobserved variables specific to variables explicitly wrote to make it a bit more clear even thought those are not shown in the figure.

\input{npmodel}

In this thesis I will mainly consider the system developed by Judea Pearl and his coauthors with methods connected to that such as do-calculus and identifying methods of back and front door criterion. There exists also other approaches of which to mention system developed by economist James Heckman (\cite{Heckman2015}). His model uses approach, derived from Haavelmos work regarding causal inference (\cite{Haavelmo1943}; \cite{Haavelmo1944}) that is applied to graphs. However Heckmans model differs from the Pearls model, which has been more widely recognized and has more literature regarding both theory and applications. Mostly these models are ways to attain same result with different methods in a practical sense. Important exception from this is instrumental variables (IV) which are easier here in Heckmans model than in the standard framework Pearl suggests --- without more restrictions that would enable for example monotonicity of functions which are however not so easy to implement --- due to its fully non-parametric nature. Also Heckman's model does not require other than standard statistical tools and which Heckman sees as a major benefit as he does not regard do-calculus very well defined as statistical concept (\cite{Heckman2015}). The philosophical framework on which causal identifications can be made also differs slightly between these approaches as do-calculus is in a way manipulating the existing model and hypothetical model creates another parallel model where inference is done.

\subsection{Do-calculus and identification}

Pearls approach includes the special notations and tools of do-calculus as he calls it. Do-calculus rules could be thought, to gain some intuition, to be similar in principle to other algebraic notations. By manipulating some expression with unwanted notations, in this case the do-notation, with the rules included in do-calculus we are able to get rid of those and change our expression so that it can be calculated with regular tools of probability theory and in this case evaluated from observational data. Thus it is just set of axioms which are applicable only in context of graph and changes do-statements to regular ordinary probabilities. One of the nice properties of do-calculus is that, originally Pearl only conjectured that only the three rules would be sufficient to find causal connections, but more recently it has been proven that, indeed these rules are a complete system for finding causal connections (\cite{Shpitser2006}; \cite{Huang2006a}). There are also rules that can be applied with less restrictive rules (\cite{Hyttinen2015}), but these approaches won't probably be as useful with economic applications as they are in machine learning applications, since the idea is to have rules to apply before declaring causal structure with even less of a strict assumptions about the underlying causal structure.

To get familiar with do-calculus and the identification methods developed for DAGs lets first introduce few new notations. When stating independence as displayed in table \ref{tab:independence} we might want to give some further conditions under which the independence is realized. If we have graph $\g$ and within that variables $X$, $Y$, $Z$ and $W$ we can use notations such as $\g_{\overline{X}\underline{Z}}$ or $\g_{\overline{XZ(W)}}$. Variable with overline in subscript of graph tells that all of the incoming arrows for this variable are blocked. Respectively with underline it denotes all of the appearing arrows from variable are blocked. When notation is used as done here with $\overline{XZ(W)}$ it denotes all $Z$-nodes, not ancestor of $W$-nodes in $\g_{\overline{X}}$ are blocking incoming edges. With these we can now read do-calculus rules.

\begin{enumerate}
    \item Insertion/deletion rule for observation:
        \begin{gather} \label{eq:do1}
            Pr(y|do(x),z,w)=Pr(y|do(x),w)\text{ if }(Y\indep Z|X,W)_{\g_{\overline{X}}}
        \end{gather}
    \item Action/observation exchange:
        \begin{gather} \label{eq:do2}
            Pr(y|do(x), do(z), w)=Pr(y|do(x),z,w)\text{ if }(Y\indep Z|X,W)_{\g_{\overline{X}\underline{Z}}}
        \end{gather}
    \item Insertion/deletion of action:
        \begin{gather} \label{eq:do3}
            Pr(y|do(x),do(z),w)=Pr(y|do(x),z,w)\text{ if }(Y\indep Z|X,W)_{\g_{\overline{XZ(W)}}}
        \end{gather}
    \captionof{lcaption}{Do-calculus rules (\cite{Pearl2009a})}
    \label{list:do}
\end{enumerate}

\noindent There exists at least two different formulation of these rules (\cite{Jud1995}; \cite{Pearl2009a}) which of I think these are the clearest and easiest to understand as well as more used in the literature.

The reason why this set of rules exists at the first place is that as graphs have only limited number of identification methods there needs to be something to manipulate graphs towards satisfying those restrictions set for identification. Identification methods can still be applied to graph without any modification in situation where necessary conditions are met. For example graph in \ref{fig:npmodel} is already fulfilling conditions for \textit{the backdoor criterion}.

\begin{itemize}
    \item[] \textbf{The Backdoor Criterion:} In relation to ordered pair $(X,Y)$ in $\g$, set of variables $Z$ satisfies backdoor criterion if there is no descendants of $X$ in $Z$ and $Z$ blocks all paths between $X$ and $Y$ containing arrow to $X$. When $\g$ satisfies these all of above mentioned criteria, causal effect is attained by backdoor adjustment: \\ 
    (\cite{Pearl2016})
    \begin{align}\label{eq:bd}
        Pr(Y=y|do(X=x))=\sum_{z}Pr(Y=y|X=x,Z=z)Pr(Z=z)
    \end{align}
\end{itemize}

\noindent This identification method can be applied to graph in figure \ref{fig:npmodel} and that will give the causal effect of $X$ to $Y$. In that graph the set of variables is only one variable $\{V_{3}\}$ that needs to be conditioned and by doing so and using the causal effect equation \ref{eq:bd} it can be measured as $\sum_{v_3}Pr(y|v_3,x)Pr(v_3)$ which is giving averaged joint distribution with $V_{3}$ conditioned. Other criteria that could be used and their adjustments are:

\begin{itemize}
    \item[] \textbf{The Frontdoor Criteria:} Set $Z$ satisfy frontdoor criterion relative to $(X,Y)$ when:
    \begin{enumerate}
        \item $Z$ intercepts all of the paths from $X$ to $Y$.
        \item No unblocked paths from $X$ to $Z$.
        \item All backdoor paths from $X$ to $Y$ are blocked by $X$.
    \end{enumerate}
    \vspace{-.2cm}
    (\cite{Pearl2016})
    in this case causal effect can be identified by adjustment formula:
    \begin{align} \label{eq:fd}
        \begin{split}
            Pr(Y&=y|do(X=x)) \\ 
            &=\sum_{z}\sum_{x'}Pr(Y=y|Z=z,X=x')Pr(X=x')Pr(Z=z|X=x)
        \end{split}
    \end{align}
    \item[] \textbf{Z-identification:} $X$, $Y$, $Z$ being disjoint set of variables and $\g$ the causal graph containing those. Causal effect $Q=Pr(y|do(x))$ is $zID$ or z-identifiable in $\g$ if one of next conditions holds: \\
    (\cite{Bareinboim2012})
    \begin{enumerate}
        \item Q is identifiable in $\g$ (this must trivially hold if identification is done).
        \item There exists $Z'\subseteq Z$ such that next holds:
        \begin{enumerate}[i.]
            \item $X$ intercepts all directed paths from $Z'$ to $Y$.
            \item $Q$ is identifiable in $\g_{\overline{Z'}}$.
        \end{enumerate}
    \end{enumerate}
\end{itemize}

These criterion are in essence very similar to backdoor criterion on applicational level. Do calculus is a bit different as it is not really identification method in a same sense, but rule book by which the expression can be modified to fulfill such. Graph in figure \ref{fig:do example} for example has two backdoor paths going through $V_{1}$ as there exists now this unobservable $U_1$  and with that the causal effect could be calculated by conditioning on $V_1$. Note that even though figure \ref{fig:do example} is showing also Heckman's hypothetical model all of the calculations are done with Pearl's do-calculus notation and right side of the model is not used in this example.

\input{do-example}

\begin{gather}
    Pr(y|do(x))=Pr(y|do(x),v_1)Pr(v_1|do(x)) \label{eq:ex1}
\end{gather}

\noindent This by itself however isn't sufficient expression to be actually estimated. However it is still possible to change the expression \ref{eq:ex1} so that it can be evaluated by do-calculus.

\begin{align}
    \sum_{v_1}Pr(y|do(x), v_1)Pr(v_1|do(x))&=\sum_{v_1}Pr(y|x, v_1)Pr(v_1|do(x)) \label{eq:ex2} \\
    &=\sum_{v_1}Pr(y|x, v_1)Pr(v_1) \label{eq:ex3}
\end{align}

So how exactly it can be done and on what it is based? First equation (\ref{eq:ex2}) is using do-rule 2 (\ref{eq:do2}) and second equation (\ref{eq:ex3}) uses do-rule 3 (\ref{eq:do3}). Even though at first glance it might seem the setup here is not identical to those, since both of these rules contain both "$W$ and $X$-variable" which are in a bit different role here or not at all in this model, by testing the conditions given it appears that both of those are actually met.

On first stage (\ref{eq:ex2}) it's possible by placing variables from figure \ref{fig:do example} to independence condition it gives $(Y \indep X|V_{1})_{\g_{\underline{X}}}$. Since this holds it is safe to remove do-operator from the first part of expression \ref{eq:ex1} making it $Pr(y|x,v_1)$. Then next part (\ref{eq:ex3}) is applying do-rule 3. Again by placing variables from this model it can be seen that the condition is holding as $(X\indep V_{1})_{\g_{\overline{X}}}$ and enables the modification suggested by rule 3 to be applied for last part of expression so it can be wrote as $Pr(v_{1})$.

This expression would now enable evaluation of causal effect since it does not contain do-operators anymore. With do-calculus it would be even possible with observational data. Causal inference with observational is somewhat controversial topic on which Pearl have strong position on supporting it (\cite{Pearl2018}). Despite that Imbens writes, economists are many times believing randomized controlled trials to be more convincing. Or alternatively if doing inference with observational data using research design modeled as such and taking advantage of situations where randomization is true for at least subpopulation of sample (\cite{imbes2020}).

With these tools we can now understand the basics of identifying causal effects from graphs as well as start to see some flaws and benefits for specific applications. Something to still mention, connected to these methods is that since graphical causal inference methods have largely been developed by computer scientist, there exists rather efficient algorithms to execute each method introduced above in practice making those quite nice to use, of course still bounded with the normal restrictions for algorithmic efficiency related to graphs.

\clearpage

\section{Applications and properties of DAG framework in context of econometric analysis} \label{section:economics}

This part of thesis will first go through some research papers done in economics using DAGs. This literature isn't very big on economics and those papers that are done use DAGs only in solving the correlation structures and deals with time series and Granger causality and thus not using identification methods.

After this some theoretical problems that are preventing use of DAGs in topics like applied micro econometric applications where also those features that really make DAGs useful in other fields like do-calculus and identification methods could be used. Here restrictions of functional form and structure appears as biggest obstacles to work out for DAGs to have possibilities for wider use in econometrics.

Lastly there will be the section going through benefits of DAGs. Dags have some aspects like clarity, as graphs are highly visual by definition, already going for them but the main benefits are promises of things it could deliver and also partly thing that might be already possible in principle but for economic use would still need some improvements for the framework as discussed in second part.

\subsection{Existing applications of DAGs in economic literature}

For the most parts economic literature that is using DAG framework as empirical method is concentrated around time series data and modeling for example price drivers or contagion and transmission channels in international trade and financial applications by establishing Granger causality in chosen model (\cite{Awokuse2003}; \cite{Bessler2003}; \cite{Yang2006}). This literature is partly quite old and uses very basic form of DAG framework similar to the one discussed before in section \ref{section:stats and ci}. However also some bit more recently published articles exist that covers very similar topics (\cite{Jayech2016}; \cite{Ji2018}) and uses models very close to those in older papers.

So strong representation of time series econometrics in association with DAGs is somewhat surprising considering that time series models are not so much featured in theoretical DAG literature and for parts it is, it tends to be about questions not really applicable in econometrics. Interest of theoretical literary is more focused around data where time discretion is less problem on data generation level. Those models also trying to establish "instantaneous" or "contemporaneous" relation which are faster than the measurement and differing from the models measuring the transition against the time change of variable or Granger causality that are used in economics (\cite{Hyttinen2017}). Also the Granger causality is somewhat problematic as a name for this method as it is not really a causal connection but rather just test of hypothesis with implications of such, rather than causality.

Already mentioned paper of Ji, Zhang and Geng (\cite{Ji2018}) is also example of something where economic researchers have found some use for DAGs. Article considers gas prices but more generally in energy economics there exists some papers like paper from Yang and Zhao \textit{Energy consumption, carbon emissions, and economic growth in India: Evidence from directed acyclic graphs} (\cite{Yang2014}). This paper considers, rather than price information time series data of emissions, energy consumption, capital formation, trade openness and GDP. The basic setup of article is otherwise very similar to other aforementioned articles and the idea is to find the transmission paths that are affecting energy consumption. In this article researchers are also able to find significant Granger causalities between variables like openness of economy, income, maybe a bit less surprisingly energy consumption and pollution but still these are not very good examples of graphical causal model.

The way those results are acquired, and the same goes for pretty much all of the articles are other time series econometric significance tests to test Granger causality and then finding the transmissions with DAG. Parts where DAGs are used in these papers like Selma Jaytech's research on 2011 stock market crash is very straightforward application. It contains basically only the use of PC algorithm (\cite{Spirtes2000}) which is algorithm for identifying the statistically significance edges. In principle it works by testing $v_{i}\in\vars$ that each $v_{i}\indep v_{j}$ where $v_{j}\in\{\pa{v_{i}}\cup\ch{v_{i}}\}$ when $i\neq j$ with some statistical test depending on the nature of variable e.g. for continuous and discrete different kind of tests are applied, if edge isn't deemed significant then removing the edge between them. Then it goes on with the same setup, but adding conditioned variables one by one as $v_{i}\indep v_{j}|\{v_{1},v_{2},\ldots,v_{n}\}$ when $v_{1},v_{2},\ldots,v_{n}\in\{\vars\setminus\{\{v_{i}\}\cup\pa{v_{i}}\cup\ch{v_{i}}\}\}$ and deleting edges if this holds. 

For other parts the only thing these articles are taking from DAG framework is the basic structure and way to present the structure which is completely comprehensible with the knowledge provided in the section \ref{section:overview} and equation \ref{eq:lmc}.
Also the fact that these are only establishing Granger causality between variables, so analysis is just concentrated on correlations and thus none provides any economic usage of the identification tools that are associated with graphs nor any use for do-calculus. Also as it is not intended to measure actual causality these graphs could not fulfill the completeness requirement of causal inference in graphs. As an example the Selma Jaytech's paper is only using prince information of stocks and bonds from different countries as determining variables for other countries price variables. It of course could not be adequate model to make complete graph as the international asset markets are not some fully endogenous self defining system, but rather there is some exogenous factors that affecting the movements. All of this might very well be sufficient for the purpose of the study, but at the same time it is making these studies, from the standpoint of graphical models and causal inference, not that great of an examples for the use of theoretical framework of DAG causal inference in economics. In other words these papers are using DAGs just as a way to present models visually and the PC algorithm as statistical test for the direction of flow of correlations in time, which makes the model kind of truncated and leaves lot on table for the part of DAG causal inference. Methods here use the DAG methods only for finding out the structure but not identifying the causality, since this setup is only able to measure Granger causality.

\subsection{Theoretical problems for economic applications}\label{subsection:problems}

It seems there isn't necessarily any one major theoretical property that would be a complete deal breaker of the use of DAGs in econometric analysis, and that has not been really the point of those who have been most skeptical on the use of DAGs for econometric causal analysis. Neither do I believe that for example Imbens on his text about \textit{The Book of Why} (\cite{PearlMackenzie18}) is, despite quite critical view on the usefulness of this approach, to say that there would not be any use cases for it in economic literature. It is rather that DAGs just are not the most convenient or realistic by assumptions in many economic applications.

However Imbes, and many of his economist and econometrician colleagues still see many problems in using DAGs that cannot be dismissed. Some of the problems are more technical in their nature and some more of a questions of taste and acquired habits like which one of the framework one happens to think is clearer on its notations potential outcomes or DAGs. I will first take  a look on the more technical side of these problems and discuss where DAG approach falls short on techniques used for econometrics and where DAG machinery might be beneficial. It should also be noted that DAGs or at least the formal notations of do-calculus are relatively new techniques and the research regarding those is very active so some of the problems mentioned here might not remain unsolved for very long.

One very evident lack in DAGs is that those cannot identify IV-setup with methods that were introduced before and the framework is not very good for that use. This is immediate outcome to the fact that graphs are usually used as nonparametric models and the functional form of variables in model is unknown from the beginning. The fact that the functions are not restricted can and especially Pearl would in general argue is good thing and adding flexibility for the model. However in IV setup this can cause some additional headache as it also leads to there not being as straight forward way to set shape restrictions for functions, like monotonicity in case of IV-regression, which are needed to get the exact estimator. There exists workarounds and other solutions like getting bounds for average causal effect which is possible in nonparametric setting (\cite{Balke1997}). There is also active research considering techniques for identifying instrumental variables in graphs as well as other identifying methods in nonparametric settings (\cite{Freyberger2017}; \cite{Freyberger2015}). One very recent working paper (\cite{Hoveid2021}) which show one way to identify IV, but this is applicable only under linearity. For the IV also Pearl has noted that if variable in question can be reasoned to really be exogenous DAG might not be the right tool for the job (\cite{PearlMackenzie18}).

This problem also extends further than only instrumental variables as in economics shape restricted functions are used in multiple places. Other occasions for restrictions might also be even more bounding as it is common for those restrictions to be consequence of economic theory, such as utility functions which are usually defined to be monotonously increasing. Economic theory of course being the factor that is in a way differing it from other kind of more general statistics inclined towards social phenomenas and the framework through which it is possible to even study the causal structures as those need the substantive knowledge of topic to have even possibility to be interpreted as causal inference at all. 

\input{equilibrium}

Another thing that is not easily applicable in DAGs is the equilibrium condition, unfortunately something quite crucial in economics. This is also immediate result from the definition of these graphs and even their name as acyclic. Equilibrium is very clearly resulting to cycle in graph as seen in figure \ref{fig:equilibrium} which is conceptualizing very simple equilibrium condition with only two exogenous variables defining interacting, endogenous variables that could be thought as price and quantity. However this is something that has been noted on other disciplines as well and thus also this is something under very active research. There has already been some research on cyclic graphs that have been able to prove the case for linear-SEM that it leads to global Markov property which is basically generalization from local Markov property extended to cover, in addition to variables also subsets of variables in directed graph (\cite{PeterSpirtes1994}).

Most recent and quite ambitious tries in a sense that it has tried to solve both cyclical components of graphs and latent confounders are made by Forré and Mooij (\cite{Forre2017}; \cite{Forre2018}; \cite{Forre2019}) in a way that still retains the Markovian properties for graph and enables non-linear functional forms. Forré and Mooij are proposing two differing models that they are calling modular-SEM (mSEM) and conditioned version of that input/output-SEM (ioSEM) that would take care at least some of those problems. The basic idea for the both of these models is to generalize methods that were presented before. By introducing these new class of graphs like hyperedged\footnote{Hyperedged graph is generalization of graph type that allows edges to connect multiple nodes.} directed graphs which contains both, directed and undirected graphs in parallel as embedded in the same model. Forré and Mooij are able to generalise methods like d-separation used in normal DAG to what they call $\sigma$-separation (\cite{Forre2017}) which is having same effect for more generalized types of graphs but which can be considered as extension of d-separation as it reduces to effectively same method as basic version when applied DAG. By doing these changes Forré and Mooij are able to generalize the separation algorithm providing representation for conditional independencies in a model which includes cycles as well as conditions for applying mSEM with the graphs (\cite{Forre2017}; \cite{Forre2018}). And then make even further modification to applied rules sot that any distributions and nonlinear functional forms are applicable as well as generalized versions of identifying algorithms (back door (\ref{eq:bd}), front door (\ref{eq:fd}), \& $zID$-methods) as well as generalized version of do-calculus (\ref{list:do})  (\cite{Forre2019}) although it should be noted that this work is partly still at the working paper stage rather than fully published. This kind of modified models, if those can be well implemented, could make a big difference for economic uses as it would allow equilibrium modeling so crucial for economists.

\subsection{Advantages and possibilities of graphical models in econometrics} \label{subsection:benefits}

As economic papers are not usually written just to be read by other economists and causal inference is many time done in settings which have also policy implications e.g. finding out how some subsidy is effecting behavior of people. Especially in those cases it might be beneficial to be able to present the models and variables with their connections as simply as possible. For this DAGs are very clear and intuitive way at least for people with no experience with statistics. However this also comes with the obvious cost of being very simplified version of what is happening so argument also goes other ways around and someone with lots of knowledge with statistical methods might find algebraic expressions as more explicit way to communicate models.

This clarity also extends to estimating models. If some very complicated structural model with many variables is estimated with for example potential outcomes framework proofs can get very complicated when complicated SEM's are applied. In DAGs those are quite easy to show with identification methods and for the many of the most usual identification method there exists complete algorithm that can do the job and as those are already prove to be complete like the algorithm to find efficient sets for back door criteria (\ref{eq:bd}) even in a bit more generalized fashion (\cite{Correa2017}). This saves user of model from doing the more technical work and instead lets researcher to focus improving the causal structure and interpreting results.

Another nice property of causal connections that are found in DAGs arise from the feature framed as problem before but also, in additions to its problems has some nice properties in other cases. Very little restrictions for functional form in DAG, the exact problem causing pain with IV's leads also to those causal observations having very little restrictions in functional sense and thus holding with very little restrictive assumptions. However for economics this is somewhat two edged sword as it is somewhat hard to introduce any restricted models for DAG which might arise from economic theory.

One repeatedly occurring problem in economics is selection bias i.e. there being some deterministic reason for the examined object to appear in sample that differs it from those not appearing. For this there already exists machinery in DAG-literature that can still work without restricting the functional form used in model (\cite{Bareinboim2014}). Selection node can be introduced to normal DAG and with that it is possible to also expands the use of model for biased samples and use models with hybrid sources where part of the estimates might be done with unbiased data and other with biased. This kind of situation might arise in situation where some of the estimators that are necessary for the identification might be more easily available e.g. from some statistical authority, but part would require using more unbalanced source. This is something that might have potential in many cases and might reduce costs of doing research and thus might for example help political decision making in areas where causal relations have been very hard to establish or doing that would have been too expensive.

Selection nodes can also help on making studies more externally valid or "transportable" as it is called in computer science literature (\cite{Pearl2011}). Term transportability is not exact synonym to external validity as it basically applying same model to new place by changing some particular part of that, but external validity is already used in some instances and in my opinion, even though not perfect, quite good to capture essence of the concept. Transportability is in a sense extension of selection nodes and in this case selection nodes are introduced to other parts of model where those are adding information about other domains of model that are some way altered when model is used in other than its original location. Also third concept related is meta-synthesis which enables integrating information from multiple models to one and thus estimating effects with back round information of the specific setup, but models originally empirically estimated somewhere else.

These would enable using once done model in some place that must have same causal structure, but there might be some factors affecting the estimates differing from the original location to be used also in the second place. This would of course be again highly useful for economics and as selection recovery this might make implementing models for different settings much cheaper and thus also possible in smaller settings which might enable better policy recommendation and better decision making for smaller units such as municipalities. Also some complicated questions like how the social security system should be renewed in could be assessed more carefully with perhaps some research done in fairly similar setting in other country. Even thought this seems very promising and usable this is of course no silver bullet solving every problem. Even though there might be interesting use cases this requires the causal structure being exactly same to retain the causal interpretation and exactly same causal structures are of course in real world very hard to find.

\clearpage

\section{Conclusion}

DAGs are already seeing lot of applications in areas such as epidemiology but still lacks use cases where economics researchers would add value for their work in their current forms. So what is the reasoning for economists to at least mostly ignore this approach? I think this can be divided to roughly four categories that vary on how easy those are solve as well as on the nature of problem. First one is simply because it is quite new and not used that much. In other words there is not that much research done with it which raises the bar for using it in new projects.

Second category contains technical questions, like functions shape restrictions. This is of course also partly guilty for the first one as it is one of the reasons that prevents use in some cases. However for these problems there might be solution on a way or at least there is many people trying to come up with those as was discussed in section \ref{subsection:problems}. Another technical by nature problem are the troubles DAGs are having with the cyclicity as the name suggests. This is making it more irrelevant and preventing the use of DAGs in econometric applications as many of those are considering some equilibrium situation. Even though Pearl have tried to show this could be solved with fairly simple solution (\cite{PearlMackenzie18}) for Imbens and Heckman this have not showed up (\cite{imbes2020}; \cite{Heckman2015}) as sufficient solution since Pearls proposal is more or less ignoring the equilibrium condition and setting demand$\rightarrow$price$\rightarrow$supply.

Last of these general categories I identified has to do more with the way graphs are done and thought. As this approach is arising from computer science departments more than from economics departments it also contains some of the weights and benefits discipline that is able to provide. One of such, that is in principle a good thing is the ways on which identification is done. It is possible to save essence of these methods to simple form and develop algorithm to do the job. However as the model or graph needs to be done by someone knowing these connections and very well to place arrows to right places. After that is done the rest is very mechanical and might feel very alluring to take answers as given even though this is completely conditional to the building the causal structure. Also there exists kind of mental asymmetry between adding and not adding edge in graph. Even though adding edges is of course important in sense that it builds the model by adding causal relationship, not adding edge is actually in a way even stronger assumption of the underlying phenomena. By not adding edge person doing the model is saying that variables are absolutely not effecting each other in comparison to adding one might range from effecting just a bit to being the sole cause. In economics it is very hard to be convinced two events are not in any way connected. One of major mechanisms causing this being such a fundamental part of economic, namely the tendency for economic agents to somehow optimize their behavior in a way that is taking into account the surrounding environment and potential outcome at given situation. This is clearly making causal structures immensely complicated as the reaction to phenomenons are dependent of such a large amount of factors and graphs assumed to be complete.

Some of the interesting future research, apart from the obvious theoretical challenges that needs to be solved for this to find more use in economics could be related to the already mentioned (\ref{subsection:benefits}) properties of selection, transportability and meta-synthesis. Both theoretical question for generalizing results of model by identifying the differing factors in research setting, that have already gained interest of researchers (\cite{Cinelli2021}) and the empirical questions that might get some answers by applying those.

Such questions where these could add value for public decision making might be here in Finland questions regarding coming reforms on social security and health care. Both of the reforms are allocating some of the responsibilities to provincial and municipal levels. However it is not attainable to have randomised controlled trials considering all of these units of governance, assuming those are not all having homogeneous effects on these reforms, due to costs associated. By doing research on more centralized manner and having broad data considering the selection within areas would allow using these models and some local, maybe already existing registry data to get at least some approximates for the local effects and further extend the ability to make informed decisions on lower levels of administration and questions like what kind of employment services would benefit each area most given the structure of population and other variables deemed relevant might be tried to answer.

%% Opinn\"aytteess\"a jokainen osa alkaa uudelta sivulta, joten \clearpage
%%
%% In a thesis, every section starts a new page, hence \clearpage
\clearpage

\addcontentsline{toc}{section}{References}
\section*{References}
%\printbibliography[
%    heading=bibintoc,
%    title={References},
%    type=none
%]
\printbibliography[
    heading=subbibintoc,
    type=article,
    title={Articles \& seminar papers}
]
\printbibliography[
    heading=subbibintoc,
    type=book,
    title={Books}
]
\printbibliography[
    heading=subbibintoc,
    type=misc,
    title={Other sources}
]

\clearpage

\end{document}