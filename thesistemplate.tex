%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                                                %%
%% An example for writting your thesis using LaTeX                %%
%% Original version by Luis Costa,  changes by Perttu Puska       %%
%% Support for Swedish added 15092014                             %%
%%                                                                %%
%% This example consists of the files                             %%
%%         thesistemplate.tex (versio 2.01)                       %%
%%         opinnaytepohja.tex (versio 2.01) (for text in Finnish) %%
%%         aaltothesis.cls (versio 2.01)                          %%
%%         kuva1.eps                                              %%
%%         kuva2.eps                                              %%
%%         kuva1.pdf                                              %%
%%         kuva2.pdf                                              %%
%%                                                                %%
%%                                                                %%
%% Typeset either with                                            %%
%% latex:                                                         %%
%%             $ latex opinnaytepohja                             %%
%%             $ latex opinnaytepohja                             %%
%%                                                                %%
%%   Result is the file opinnayte.dvi, which                      %%
%%   is converted to ps format as follows:                        %%
%%                                                                %%
%%             $ dvips opinnaytepohja -o                          %%
%%                                                                %%
%%   and then to pdf as follows:                                  %%
%%                                                                %%
%%             $ ps2pdf opinnaytepohja.ps                         %%
%%                                                                %%
%% Or                                                             %%
%% pdflatex:                                                      %%
%%             $ pdflatex opinnaytepohja                          %%
%%             $ pdflatex opinnaytepohja                          %%
%%                                                                %%
%%   Result is the file opinnaytepohja.pdf                        %%
%%                                                                %%
%% Explanatory comments in this example begin with                %%
%% the characters %%, and changes that the user can make          %%
%% with the character %                                           %%
%%                                                                %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%% Uncomment one of these:
%% the 1st when using pdflatex, which directly typesets your document in
%% pdf (use jpg or pdf figures), or
%% the 2nd when producing a ps file (use eps figures, don't use ps figures!).
\documentclass[main=english,12pt,a4paper,pdftex,econ,utf8]{aaltothesis}
\usepackage{comment}
\usepackage{caption}
\usepackage{capt-of}
\usepackage{libertine}
\usepackage{adjustbox}
%\documentclass[english,12pt,a4paper,dvips]{aaltothesis}

%% To the \documentclass above
%% specify your school: arts, biz, chem, elec, eng, sci, econ
%% specify the character encoding scheme used by your editor: utf8, latin1

%% Use one of these if you write in Finnish (see the Finnish template):
%%
%\documentclass[finnish,12pt,a4paper,pdftex,elec,utf8]{aaltothesis}
%\documentclass[finnish,12pt,a4paper,dvips]{aaltothesis}

\usepackage{graphicx}

%% Use this if you write hard core mathematics, these are usually needed
\usepackage{amsfonts,amssymb,amsbsy,amsmath,bm}
\usepackage{color, soul}
\usepackage{pst-node, auto-pst-pdf}
\usepackage{caption}
\captionsetup{labelfont={bf}}
%% Use the macros in this package to change how the hyperref package below 
%% typesets its hypertext -- hyperlink colour, font, etc. See the package
%% documentation. It also defines the \url macro, so use the package when 
%% not using the hyperref package.
%%
%\usepackage{url}

%% Use this if you want to get links and nice output. Works well with pdflatex.
\usepackage{tikz}
\usepackage{verbatim}
\usepackage{forest}
\usepackage{etoolbox}
\usepackage{multirow}
\usepackage{adjustbox}
\usetikzlibrary{arrows,trees,positioning}
\tikzstyle{circleobject}=[circle,fill=white,draw,line width=0.5mm]
\tikzstyle{line}=[draw]
\tikzstyle{arrow}=[draw, -latex]
\usetikzlibrary{arrows.meta}


\tikzset{%
    /forest,
    forest node/.style={circle, inner sep=0pt, text centered},
    arn n/.append style={text=white, font=\sffamily\bfseries, draw=black, text width=1.5em},
    arn r/.append style={text=red, draw=red, text width=1.5em, very thick},
  }
\usepackage{hyperref}
\usepackage{csquotes}
\usepackage{enumerate}
\usepackage{newtxtext,newtxmath}
\hypersetup{
    pdfpagemode=UseNone, 
    colorlinks=true,
    filecolor=blue,
    pdfstartview=FitH,
    urlcolor=blue,
    linkcolor=red,
    citecolor=black,
    pdftitle={Default Title, Modify},
    pdfauthor={Your Name},
    pdfkeywords={Modify keywords},
    urlcolor=blue
}

\usepackage[
    backend=biber,
    sorting=nyt,
    style=authoryear,
    citestyle=apa
]{biblatex}
\addbibresource{library.bib}
\addbibresource{manual.bib}
\linespread{1.5}
%----------------- NEW COMMANDS -----------------
\newcommand{\indep}{\perp \!\!\! \perp}
\newcommand{\nindep}{\not\!\indep}
\newcommand{\dsep}{\stackrel{d}{\indep}}
\let\emptyset\varnothing
\newcommand{\ch}[1]{Ch(#1)}
\newcommand{\pa}[1]{Pa(#1)}
\newcommand{\de}[1]{De(#1)}
\newcommand{\z}{\mathcal{Z}}
\newcommand{\g}{\mathcal{G}}
\newcommand{\e}{\bm{\epsilon}}
\newcommand{\vars}{\bm{V}}
\newcommand{\unobs}{\bm{U}}
\newcommand{\wrap}[1]{\parbox{.33\linewidth}{\vspace{1.5mm}#1\vspace{1mm}}}
\DeclareCaptionType{lcaption}[List][List of things]
%------------------------------------------------
%% All that is printed on paper starts here
\begin{document}

%% Change the school field to specify your school if the automatically 
%% set name is wrong
% \university{aalto-yliopisto}
% \university{aalto University}
% \school{Sähkötekniikan korkeakoulu}
% \school{School of Electrical Engineering}

%% Only for B.Sc. thesis: Choose your degree programme. 
\degreeprogram{Bachelor's Programme in Economics}
%%

%% ONLY FOR M.Sc. AND LICENTIATE THESIS: Specify your department,
%% professorship and professorship code. 
%%
\department{Department of Economics}
%\professorship{Circuit theory}
%%

%% Valitse yksi näistä kolmesta
%%
%% Choose one of these:
\univdegree{BSc}
%\univdegree{MSc}
%\univdegree{Lic}



%% Your own name (should be self explanatory...)
\author{Santeri Väätäjä}

%% Your thesis title comes here and again before a possible abstract in
%% Finnish or Swedish . If the title is very long and latex does an
%% unsatisfactory job of breaking the lines, you will have to force a
%% linebreak with the \\ control character. 
%% Do not hyphenate titles.
%% 
\thesistitle{\mbox{Directed acyclic graph causal inference framework} and its applications in econometrics}

\place{Espoo}

%% For B.Sc. thesis use the date when you present your thesis. 
%% 
%% Kandidaatintyön päivämäärä on sen esityspäivämäärä! 
\date{24.8.2021}

%% B.Sc. or M.Sc. thesis supervisor 
%% Note the "\" after the comma. This forces the following space to be 
%% a normal interword space, not the space that starts a new sentence. 
%% This is done because the fullstop is not the end of the sentence that
%% should be followed by a slightly longer space but is to be followed
%% by a regular space.
%%
\supervisor{Prof. Pauli Murto} %{Prof.\ Pirjo Professori}

%% B.Sc. or M.Sc. thesis advisors(s). You can give upto two advisors in
%% this template. Check with your supervisor how many official advisors
%% you can have.
%%
%\advisor{Prof.\ Pirjo Professori}
\advisor{Asst. Prof. Ciprian Domnisoru}
%\advisor{M.Sc.\ Polli Pohjaaja}

%% Aalto logo: syntax:
%% \uselogo{aaltoRed|aaltoBlue|aaltoYellow|aaltoGray|aaltoGrayScale}{?|!|''}
%%
%% Logo language is set to be the same as the document language.
%% Logon kieli on sama kuin dokumentin kieli
%%
\uselogo{aaltoRed}{''}

%% Create the coverpage
%%
\makecoverpage


%% Note that when writting your master's thesis in English, place
%% the English abstract first followed by the possible Finnish abstract

%% English abstract.
%% All the information required in the abstract (your name, thesis title, etc.)
%% is used as specified above.
%% Specify keywords
%%
%% Kaikki tiivistelmässä tarvittava tieto (nimesi, työnnimi, jne.) käytetään
%% niin kuin se on yllä määritelty.
%% Avainsanat
%%
\keywords{directed acyclic graphs, causal inference, nonparametric methods}
%% Abstract text
\begin{abstractpage}[english]
This thesis aims to first provide basic understanding of directed acyclic graph causal inference and then apply this knowledge on how it is affecting its applicability to econometric research. First part is going through theoretical literature on graphs and statistical graphical models. This thesis will especially concentrate on model developed largely by Judea Pearl with its identification machinery. Then the theory is used to show some specific features considering the framework and taking a look at pre-existing literature in economics regarding this kind of model. Finally, some benefits and possibilities currently as well as in future and some possible developments and their effects for possibilities in economics are discussed. 

This part concludes that there is quite a lot of challenges considering these models such as problems with instrument variables as well as with other applications requiring shape restrictions for functions used. However there also already exist use cases such as finding good control variables and things having great promises as the methods based on selection node techniques.
\begin{comment}
Your abstract in English. Try to keep the abstract short; approximately 
100 words should be enough. The abstract explains your research topic, 
the methods you have used, and the results you obtained.  
Your abstract in English. Try to keep the abstract short; approximately 
100 words should be enough. The abstract explains your research topic, 
the methods you have used, and the results you obtained.  

Your abstract in English. Try to keep the abstract short; approximately 
100 words should be enough. The abstract explains your research topic, 
the methods you have used, and the results you obtained.  
Your abstract in English. Try to keep the abstract short; approximately 
100 words should be enough. The abstract explains your research topic, 
the methods you have used, and the results you obtained.  
\end{comment}    
\end{abstractpage}

%% Force a new page so that the possible English abstract starts on a new page
%%
%% Pakotetaan uusi sivu varmuuden vuoksi, jotta 
%% mahdollinen suomenkielinen ja englanninkielinen tiivistelmä
%% eivät tule vahingossakaan samalle sivulle
\begin{comment}
\newpage
%
%% Abstract in Finnish.  Delete if you don't need it. 
\thesistitle{Opinnäyteohje}
\advisor{TkT Olli Ohjaaja}
\degreeprogram{Electronics and electrical engineering}
\department{Radiotieteen ja -tekniikan laitos}
\professorship{Piiriteoria}
%% Avainsanat
\keywords{Vastus, Resistanssi,\\ Lämpötila}
%% Tiivistelmän tekstiosa
\begin{abstractpage}[finnish]
  Tiivistelmässä on lyhyt selvitys (noin 100 sanaa)
  kirjoituksen tärkeimmästä sisällöstä: mitä ja miten on tutkittu,
  sekä mitä tuloksia on saatu. 
  Tiivistelmässä on lyhyt selvitys (noin 100 sanaa)
  kirjoituksen tärkeimmästä sisällöstä: mitä ja miten on tutkittu,
  sekä mitä tuloksia on saatu. 

  Tiivistelmässä on lyhyt selvitys (noin 100 sanaa)
  kirjoituksen tärkeimmästä sisällöstä: mitä ja miten on tutkittu,
  sekä mitä tuloksia on saatu. 
  Tiivistelmässä on lyhyt selvitys (noin 100 sanaa)
  kirjoituksen tärkeimmästä sisällöstä: mitä ja miten on tutkittu,
  sekä mitä tuloksia on saatu. 
  Tiivistelmässä on lyhyt selvitys (noin 100 sanaa)
  kirjoituksen tärkeimmästä sisällöstä: mitä ja miten on tutkittu,
  sekä mitä tuloksia on saatu. 
\end{abstractpage}

\end{comment}
%% Force new page so that the Swedish abstract starts from a new page
\newpage
%
%% Swedish abstract. Delete if you don't need it. 
%% 

%% Table of contents.
{
\hypersetup{linkcolor=black}
\thesistableofcontents
}

%% Symbols and abbreviations
\mysection{Symbols and abbreviations}

\subsection*{Symbols}

\begin{tabular}{ll}
$\vars$ & set of variables $\{V_{1},V_{2},\ldots,V_{N}\}$ \\
$\unobs$ & set of unobserved $\{U_{1},U_{2},\ldots,U_{N}\}$ \\
$\e$ & set of edges $\{\epsilon_{1},\epsilon_{2},\ldots,\epsilon_{N}\}$ \\
$\g$ & graph \\
$\z$ & subgraph
\end{tabular}

\subsection*{Operators}

\begin{tabular}{ll}
$\indep$ & independent \\
$\nindep$ & not independent \\
%$\dsep$ & d-separation \\
$\pa{\bm{\cdot}}$ & parents of given node \\
$\ch{\bm{\cdot}}$ & children of given node \\
$\de{\bm{\cdot}}$ & descendants of given node \\
$Pr(\bm{\cdot})$ & probability
\begin{comment}
$\nabla \times \mathbf{A}$              & curl of vectorin $\mathbf{A}$\\
$\displaystyle\frac{\mbox{d}}{\mbox{d} t}$ & derivative with respect to 
variable $t$\\[3mm]
$\displaystyle\frac{\partial}{\partial t}$  & partial derivative with respect 
to variable $t$ \\[3mm]
$\sum_i $                       & sum over index $i$\\
$\mathbf{A} \cdot \mathbf{B}$    & dot product of vectors $\mathbf{A}$ and 
$\mathbf{B}$
\end{comment}
\end{tabular}

\subsection*{Abbreviations}
\begin{tabular}{ll}
CI  & causal inference \\
DAG & directed acyclic graph \\
DCG & directed cyclic graph \\
SEM & structural equation model \\
LMC & local Markov condition \\
IV  & instrumental variable \\
VAR & vector autoregression \\
ECM & error correction model
\end{tabular}


%% Tweaks the page numbering to meet the requirement of the thesis format:
%% Begin the pagenumbering in Arabian numerals (and leave the first page
%% of the text body empty, see \thispagestyle{empty} below).
%% Additionally, force the actual text to begin on a new page with the 
%% \clearpage command.
%% \clearpage is similar to \newpage, but it also flushes the floats (figures
%% and tables).
%% There is no need to change these
%%
\cleardoublepage
\storeinipagenumber
\pagenumbering{arabic}
\setcounter{page}{1}


%% Text body begins. Note that since the text body
%% is mostly in Finnish the majority of comments are
%% also in Finnish after this point. There is no point in explaining
%% Finnish-language specific thesis conventions in English. Someday 
%% this text will possibly be translated to English.
%%
%\section{Introduction}

%% Ensimm\"ainen sivu tyhj\"aksi
%% 
%% Leave first page empty
%\thispagestyle{empty}
%\clearpage

\section{Introduction}

Declaring causal inference (CI) has been for a long-time debated area, in social sciences in general, and respectively in economics. It is naturally very interesting for scientists across the fields to establish more profound connections than correlation to events affecting their field studies. It also works as a way for economists to have larger effect on society as it enables policy advises to have more solid foundation on the effects of particular policy changes beforehand.

Purpose of this thesis is to give an overview of one of such methods that can be used to infer causal connections from data. Method discussed in this thesis, directed acyclic graph causal inference (DAG CI), is a method used in multiple fields like computer science and epidemiology, but have had smaller role in social sciences even though it has sparked some debate. However in recent years there has been more interest also from these fields of study and one of the main advocates of this method, a computer scientist who has done research on this method, Judea Pear is arguing that DAG methods should be used also in economics (\cite{pearl_2014}) and having discussions with economists such as Guido Imbens over articles (\cite{Imbens2014}; \cite{imbes2020}) and James Hekcman and Rodrigo Pinto (\cite{Heckman2015}) about the suitability of the framework in economics.

First content section \ref{section:overview} of this thesis tries to explain most essential set theory concepts considering graph theory, that are prerequisites for understanding the statistical interpretation on DAGs. This part is mainly based on Pearls older paper going through the fundamentals of this method (\cite{Pearl1998}) and textbook about CI (\cite{Peters2017}).

Second section \ref{section:stats and ci} builds on top of the first and starts to give statistical features for graphs and goes through some of the CI tools used with graphs. Properties of model and methods introduced here are needed later to understand why some specific parts of the model or tool set associated with it are either useful or causing troubles in econometric applications. Two important topics here, developed largely by Pear and his coauthors, are \textit{do-calculus} and \textit{identification methods} in more general sense and literary considering these will contain multiple articles by Pearl for definitions of these tools. In addition for that some contrasts are made with alternative choices that might be used like hypothetical graphs by Heckman (\cite{Heckman2015}) which introduces a bit differing way to use graphs in CI applications.

Last section (\ref{section:economics}) is solely dedicated for finding out the economics perspective. At the beginning some of the existing empiric papers using at least in some forms of DAGs are introduced. These are macroeconomics articles considering Granger causality and thus not using identification strategies offered by DAGs. This is also one of the problems in this thesis that there is not much empirical economic research that would yet be done with DAGs. Thus also much of this thesis is centered more towards the possible benefits and shortcomings which are gone through more systematically in sections \ref{subsection:problems} and \ref{subsection:benefits}. These parts are mostly looking at some newer research and working papers considering some of the still existing problems for economics such as implementation of equilibrium condition and instrument variables as well as trying to come up with some of the possible current merits and features which are still under development as this is written.

In the last part of the section I try to find out how this model would benefit economic research especially in policy settings and features which might make it much accessible to conduct research in these cases compared to randomized controlled trials. These are due to possibility to handle selection, transport the model to different locations without necessarily estimating it again from the beginning and meta-analysis or synthesis approaches enabling combining information.

\clearpage

\section{Overview of directed acyclic graphs} \label{section:overview}

This section provides an overview of general structure of graphs as well as what kind of notations are used with graphs in general and with statistical interpretation. First the basics of graphs as structure and terms used as a basis for the statistical interpretations are gone through. This should provide necessary concepts needed to understand the framework as well as at later stage help understand the features either causing problems when DAGs are used in economic settings or features that might benefit economic analysis.

Secondly the operators used to define further properties that make graphs useful in statistical applications are introduced. These properties are very generally applicable for graphs also outside the CI framework and can be given for graphs as a general mathematical object. Implications of those are highly important for further discussion and to understand the building blocks of the statistical model as well as defining features such as independence in model.

\subsection{Directed acyclic graph as structure}

DAGs are at simplest just set containing variables $\vars$ that have some extra restrictions regarding the way variables, or nodes in graph context, are connected withing the graph. Variables in $\vars$ themselves do not have many restrictions. Graphs in this use should not be mixed with another meaning of word in mathematics. Graph showing for example picture of some function on x and y-axis is entirely different thing.

Aforementioned restrictions for DAGs are defining the set of possible relations for variables in the graph in hand as well as defining not permitted structures in the topological paths. Paths build up from the edges contained in $\e$ which contains the relational information of graph. Edges in DAGs thus have property of direction and information where edge begins and where it ends. Edges and directions of a graph are not symmetric relations in case of DAGs since $\e\subseteq \{\vars^2\setminus(i,i)\}$ where $\epsilon_i=(i,j)\neq(j,i)$ which is necessary but not sufficient condition for acyclicity. When the graph is directed it leads to the topological ordering necessarily being proceeding at every point and never having an edge leading backwards in topological order as figure \ref{fig:topological} shows (\cite{Peters2017}).

\input{topological_ordering}

In this thesis specially directed and acyclic graphs are discussed and thus edges have the direction information or the information of in which direction each edge can be travelled. Acyclicity means that one node cannot exist twice in any possible path. In case node would exist twice in path it could appear infinitely many times in path due to the nature of cycles. This radically reduces the number of algorithms and methods that can be applied to the graph as well as the assumptions that can be made in the context of the graph allowing statistical interpretations. Breaking acyclicity also prevents use of the CI methods in similar form presented in this thesis. If there would exist cycles graph becomes directed cyclical graph and DCGs are fundamentally non recursive structures. This breaks some of the relationships that DAGs have, and which will be discussed in more detail and in economic context in section \ref{section:economics} (\cite{Heckman2015}). In other words, cyclicity introduces feedback mechanism for the structure which would lead to the graph being recursive and variables would therefore have causal effect with themselves. This is making the handling of model much harder, and methods introduced for directed acyclic graphs are not many times applicable in these cases at least without some modification or generalization of those. Theory for these different structures is not discussed in this thesis in depth, but some of the properties for those models are discussed in section \ref{section:economics} due to their high significance or possible significance for economic applications.

\subsection{Graph operators}

As graphs have additional conditions defined compared to normal set of objects there also exists operators that graphs have specially defined for them. These operators are also necessary for the causal analysis as these give tools for analyze and define parts of graph and differentiate subgraphs with specific features from the rest.

First concept to know is a path. Path in directed graph consists of variables that have consecutive edges connecting them so that for every variable in path, $V_{i}\rightarrow V_{i+1}$ holds. These also have role in CI as they describe the routes that causal relationships are influencing other variables. Also tightly connected to paths are the colliders, which always exists in relation to paths. Collider in path is structure where aforementioned condition does not hold but there exist directed edge so $V_{i}\rightarrow V_{i-1}$. Example of such can be seen in figure \ref{fig:topological} DAG where path from $V_{1}$ to $V_{3}$ has subgraph $V_{1}\rightarrow V_{3}$ where no collider exist. Two of the other paths clearly have colliders as $V_{1}\rightarrow V_{2}\rightarrow V_{4}\rightarrow V_{5}\leftarrow V_{3}$ has $V_{5}$ forming collider and $V_{1}\rightarrow V_{2}\rightarrow V_{4}\leftarrow V_{3}$ has $V_{4}$ as collider node.

Path such as $V_{2}\leftarrow V_{1}\rightarrow V_{3}$ in figure \ref{fig:topological} are still further called fork. In fork middle node has two edges emerging from it. Path such as $V_{1}\rightarrow V_{3}\rightarrow V_{5}$ are called chains and in this type of path all edges are parallel.

With paths it is possible define further relations, usually called kinship, for nodes or subgraphs. These operators are also needed to analyze causal structure in graphs since those enable distinguishing independence in graph and thus to define the statistical estimates for causality. Ancestor of variable $V_{i}$ in directed graph, is such other variable appearing before $V_{i}$ in topological order that has direct path to $V_{i}$. If node is appearing only one edge before $V_{i}$ it is called parent node and set of parents is denoted as $\pa{\bm{\cdot}}$. Respectively if there is direct path from $V_{i}$ to some other node it is called its descendant and set of descendants is denoted by $\de{\bm{\cdot}}$. If there is path from $V_{i}$, only one edge long, node is called children $\ch{\bm{\cdot}}$.

\clearpage

\section{Directed acyclical graphs for statistics and causal inference} \label{section:stats and ci}

Graphs need or at least most of the time are used with, some special mathematical machinery when those are applied for CI. This section will take an overview to statistical applications of graphs and especially Markovian or causal graphs by going through some of the most fundamental tools to understand for CI in graphical models on conceptual level.

First part will be defining the way DAGs bring together necessary conditions for conditional independence and provides one of the most crucial concepts for the probabilistic interpretation, local Markov condition. With d-separation it is possible to isolate the necessary variables by conditioning the right set of variables and with the combination of these two we can start to make statistical sense within graphs.

With the help of local Markov condition, we can now factorize conditional probabilities out of the set of variables by conditioning the correct set of variables. For the first time everything talked about the general structure, operators and methods will come together and make it possible for the graph to make sense in statistical sense. At this point it becomes possible to define the model within which the causal analysis is going to operate.

Third part then introduces the ways to identify causal effects between variables and few of the most common strategies for that. In addition, do-calculus which is distinguishing DAGs from other causal frameworks and having its impact on the popularity of the model. This part will cover the mathematical machinery and the rules associated with it after which main components of the DAG framework in its simplest form is covered.

\subsection{D-separation and independence} \label{subsection:d and indep}

D-separation is only used in context of graphical models and implies independence between two variables within graph as it is the condition set by which independence can be decided. These conditions are shown in table \ref{tab:independence} which also illustrates how d-separation ties the concept of independence into graphs. Variables can be independent by two ways in graph. First one is if only connecting paths are colliders. That leads two variables being independent without any further action or conditioning. Second way to establish d-separation is to have ordered pair of variables $(X, Y)$ be separated from each other by set of variables $\z$. Set of variables $\z$ however have few extra conditions for the variables it is containing:

\begin{enumerate}
    \item Variables in $\z$ are in path between variables $X$ and $Y$ in paths that are either chains or forks. This would correspond controlling $\{V_{2},V_{3}\}$ or $\{V_{2},V_{4}\}$ in figure \ref{fig:topological} if the exposure variable is $V_{1}$ and outcome variable $V_{5}$.
    \item Variables of $\z$ are not variables or descendants of variables that construct collider on path.
\end{enumerate}

From above can be seen there can exist multiple efficient\footnote{Set containing minimum amount of variables that fulfills the conditions for d-separation.} subsets of $\z$ even though also conditioning all other variables than colliders or their descendants would also lead to proper d-separation (\cite{Pearl2016}). These rules are also illustrated by table \ref{tab:independence}. However choosing good set of variables to control instead of all of $\z$ can also be utilized in situation where for example measuring some variable would be harder than others. Further, d-separation can help us make testable hypotheses that are implied by the graphical model. This is something setting graphical models apart from other types of CI methods by its very mechanical character and also key part in enabling causal claims from observational data.

\input{independence table}

To have independence with these conditions, model should also be Markovian and fulfill local Markov condition (LMC). Model is considered Markovian when all the unobservable variables or residuals are jointly independent, and the model is acyclic. However sometimes some of those unobservables variables are showed in graph and if we know which variables it is affecting i.e., which variables are having some jointly dependent unobservable variables. By including unobservables making variables jointly dependent, it is still possible to work with it. For the causal claim to be testable some extra requirements need to be taken care of while choosing $\z$ as those unobservables open new paths that need to be conditioned or in case of collider not conditioned. These kinds of models are called semi-Markovian.

Local Markov condition on the other hand is the condition that is needed to provide the independecy by d-separation and thus also translate the graphical properties of a graph to causal claim (\cite{Heckman2015}). LMC is telling us that the variables are independent of other ancestors they have, conditional on their parents. Equation \ref{eq:lmc} is saying that all $v_i$ in $\vars$ are independent of the set of variables containing its other ancestors than parent if conditioned with its parent. Formally defined LMC is:

\begin{gather} \label{eq:lmc}
    \forall v_{i}\in\vars\text{: }v_{i}\indep\vars\setminus\{\de{v_{i}}\cup \{v_{i}\}\}\,|\,\pa{v_{i}}
\end{gather}

Now with the LMC condition and graphoid statements that define the independence conditions, and were found out to hold in undirected graphs (\cite{Paz1985}) and later in directed (\cite{Pearl1986}), the concept of independence starts to make sense in graphical context. These conditions need to be met for conditional independence to hold in graphs. With these it also gets possible to start to use DAGs for statistical purposes.

\subsection{Statistical interpretation of directed acyclical graphs} \label{subsection:stat}

From LMC (\ref{eq:lmc}) it is finally possible to derive the general factorization of variables in graphs. As the LMC suggests the parents of node are somewhat special group in context of the probabilistic interpretation by saying that other ancestors than parents are in fact irrelevant for the factorizing of probability distribution for variable. This is same as with any probability calculation but as mentioned in section \ref{subsection:d and indep} it is also found to be applicable for graphs. Joint distribution for variables $Pr(V_1,V_2,\ldots,V_n)$ in recursive model can be derived from LMC (\ref{eq:lmc}). With $|\vars|=N$ variables that are ordered as $V_1,V_2,\ldots,V_{n-1}$ not being descendants of $V_n$ and $V_{n+1},\ldots,V_{N}$ being descendants of the same variable $V_n$, implying $\pa{V_n}\subseteq V_1,V_2,\ldots,V_{n-1}$ (\cite{Heckman2015}). With this and assumption regarding exogenous variables $\unobs$ to be jointly independent, it is possible to show conditional independence being:

\begin{align} \label{eq:factor}
    \begin{split}
        Pr(V_1,V_2,\ldots,V_{n})&=\prod_{V_{n}\in\vars}Pr(V_{n}|V_1,V_2,\ldots,V_{n-1}) \\
        &=\prod_{V_{n}\in\vars}Pr(V_{n}|\pa{V_{n}})
    \end{split}
\end{align}

\noindent With factorization defined it gets possible to give some meaningful causal interpretation properties for graphs as probability is now meaningful concept in context of graph.

To start making sense of the model with data and having causal interpretation for the relations of functions between nodes those need to be defined. There have been and is multiple different approaches for this. One of the first approaches was to write SEM with linear equations like $y=\beta x+u$ and then give the causal relation in graph based on the theoretical or observed knowledge of situation (\cite{Wright1921}). This can however be generalized also to non-parametric functions which is for now on thought to be the default model here. SEM is constructed so that it contains functions for all observed variables (\cite{Pearl2008}), however in model of figure \ref{fig:npmodel} each function has all of the unobserved variables specific to variables explicitly written to make it a bit more clear even though those are not shown in the figure.

\input{npmodel}

\subsection{Do-calculus and identification}

Pearls approach includes the special notations and tools of do-calculus as he calls it. Do-calculus rules could be thought to be similar in principle to other algebraic expressions. By manipulating some expression with unwanted notations, in this case the do-notation, with the rules included in do-calculus we can get rid of those. This enables estimation with regular tools of probability theory as equations \ref{eq:ex2} \& \ref{eq:ex3} will demonstrate. Thus, it is just set of axioms which are applicable only in context of graph and changes do-statements to regular probabilities. One of the nice properties of do-calculus is that, originally Pearl only conjectured that only the three rules would be sufficient to find causal connections. More recently it has been proven that, indeed these rules are a complete system for finding causal connections (\cite{Shpitser2006}; \cite{Huang2006a}). There are also rules that can be applied with less restrictive rules (\cite{Hyttinen2015}), but these approaches won't probably be as useful with economic applications as they are in machine learning applications. Idea with these rules is to apply those before declaring causal structure with even less strict assumptions about the underlying causal structure, while economists usually tend to build models based on some theoretical framework.

To get familiar with do-calculus and the identification methods developed for DAGs lets first introduce few new notations. When stating independence as displayed in table \ref{tab:independence} we might want to give some further conditions under which the independence is realized. If we have graph $\g$ and within that variables $X$, $Y$, $Z$ and $W$ we can use notations such as $\g_{\overline{X}\underline{Z}}$ or $\g_{\overline{XZ(W)}}$. Variable with overline in subscript of graph tells that all the incoming arrows for this variable are blocked. Respectively with underline it denotes all the appearing arrows from variable are blocked. When notation is used as done here with $\overline{XZ(W)}$ it denotes all $Z$-nodes, not ancestor of $W$-nodes in $\g_{\overline{X}}$ are blocking incoming edges. With these we can now read do-calculus rules.

\begin{enumerate}
    \item Insertion/deletion rule for observation:
        \begin{gather} \label{eq:do1}
            Pr(y|do(x),z,w)=Pr(y|do(x),w)\text{ if }(Y\indep Z|X,W)_{\g_{\overline{X}}}
        \end{gather}
    \item Action/observation exchange:
        \begin{gather} \label{eq:do2}
            Pr(y|do(x), do(z), w)=Pr(y|do(x),z,w)\text{ if }(Y\indep Z|X,W)_{\g_{\overline{X}\underline{Z}}}
        \end{gather}
    \item Insertion/deletion of action:
        \begin{gather} \label{eq:do3}
            Pr(y|do(x),do(z),w)=Pr(y|do(x),z,w)\text{ if }(Y\indep Z|X,W)_{\g_{\overline{XZ(W)}}}
        \end{gather}
    \captionof{lcaption}{Do-calculus rules (\cite{Pearl2009a})}
    \label{list:do}
\end{enumerate}

\noindent There exists at least two different formulation for these rules (\cite{Jud1995}; \cite{Pearl2009a}) of which I think these are the cleaner one and easier to understand as well as more used in the literature.

The reason why this set of rules exists is to uncover other causal connections not identifiable with these three simpler schemes (\ref{eq:bd}, \ref{eq:fd} \& \ref{item:zid}). Do-calculous enables us to make sense of more complicated situations and find all causal connections due to the completeness (\cite{Pearl2016}). It also packs these methods in algorithmic form, making identification easy for computer. Identification methods can still be applied to graph without any modification in situation where necessary conditions are met from the beginning. For example graph in \ref{fig:npmodel} is already fulfilling conditions for \textit{the backdoor criterion}.

\begin{itemize}
    \item[] \textbf{Backdoor Criterion:} In relation to ordered pair $(X,Y)$ in $\g$, set of variables $Z$ satisfies backdoor criterion if there is no descendants of $X$ in $Z$ and $Z$ blocks all paths between $X$ and $Y$ containing arrow to $X$. When $\g$ satisfies these all of above mentioned criteria, causal effect is attained by backdoor adjustment: \\ 
    (\cite{Pearl2016})
    \begin{align}\label{eq:bd}
        Pr(Y=y|do(X=x))=\sum_{z}Pr(Y=y|X=x,Z=z)Pr(Z=z)
    \end{align}
\end{itemize}

\noindent This identification method can be applied to graph in figure \ref{fig:npmodel} giving causal effect of $X$ to $Y$. In this graph the adjustment set of variables, given by backdoor criterion, is only one variable $\{V_{3}\}$ and needs to be conditioned. By doing so and using the causal effect equation \ref{eq:bd} it can be estimated as $\sum_{v_3}Pr(y|v_3,x)Pr(v_3)$ which is giving averaged joint distribution with $V_{3}$ conditioned. Other criteria that could be used are:

\begin{itemize}
    \item[] \textbf{Frontdoor Criteria:} Set $Z$ satisfy frontdoor criterion relative to $(X,Y)$ when:
    \begin{enumerate}
        \item $Z$ intercepts all of the paths from $X$ to $Y$.
        \item No unblocked paths from $X$ to $Z$.
        \item All backdoor paths from $X$ to $Y$ are blocked by $X$.
    \end{enumerate}
    \vspace{-.2cm}
    (\cite{Pearl2016})
    in this case causal effect can be identified by adjustment formula:
    \begin{align} \label{eq:fd}
        \begin{split}
            Pr(Y&=y|do(X=x)) \\ 
            &=\sum_{z}\sum_{x'}Pr(Y=y|Z=z,X=x')Pr(X=x')Pr(Z=z|X=x)
        \end{split}
    \end{align}
    \item[] \textbf{Z-identification:} $X$, $Y$, $Z$ being disjoint set of variables and $\g$ the causal graph containing those. Causal effect $Q=Pr(y|do(x))$ is $zID$ or z-identifiable in $\g$ if one of next conditions holds: \\
    (\cite{Bareinboim2012})
    \begin{enumerate}
        \item\label{item:zid} Q is identifiable in $\g$ (this must trivially hold if identification is done).
        \item There exists $Z'\subseteq Z$ such that next holds:
        \begin{enumerate}[i.]
            \item $X$ intercepts all directed paths from $Z'$ to $Y$.
            \item $Q$ is identifiable in $\g_{\overline{Z'}}$.
        \end{enumerate}
    \end{enumerate}
\end{itemize}

These criteria are in essence very similar to backdoor criterion on applicational level but do-calculus works bit differently as those rules can be applied multiple times to acquire the estimator. Graph in figure \ref{fig:do example} for example has two backdoor paths going through $V_{1}$ as there exists now this unobservable $U_1$. Causal effect could be calculated by conditioning on $V_1$. Note that even though figure \ref{fig:do example} is showing also Heckman's hypothetical model all of the calculations are done with Pearl's do-calculus notation and right side of the model is not used in this example. In Heckman's framework this would happen with tools provided by standard probability theory.

\input{do-example}

\begin{gather}
    Pr(y|do(x))=Pr(y|do(x),v_1)Pr(v_1|do(x)) \label{eq:ex1}
\end{gather}

\noindent This however, by itself is not sufficient expression to be actually estimated. However it is still possible to manipulate expression \ref{eq:ex1}  with do-calculus so that it can be estimated.

\begin{align}
    \sum_{v_1}Pr(y|do(x), v_1)Pr(v_1|do(x))&=\sum_{v_1}Pr(y|x, v_1)Pr(v_1|do(x)) \label{eq:ex2} \\
    &=\sum_{v_1}Pr(y|x, v_1)Pr(v_1) \label{eq:ex3}
\end{align}

First equation \ref{eq:ex2} is using do-rule 2 (\ref{eq:do2}) and second equation \ref{eq:ex3} uses do-rule 3 (\ref{eq:do3}). Even though at first glance it might seem the setup here is not identical to those as both rules contain both "$W$ and $X$-variable" from do-calculus rules \ref{list:do}, which do not exist in this model. By testing the given conditions, it appears that both of those are actually met and those can be applied.

Rule 2 is first applied to expression \ref{eq:ex2} and it is applicable since placing variables from figure \ref{fig:do example} to independence condition yields independence $(Y \indep X|V_{1})_{\g_{\underline{X}}}$. By this, do-operator of expression \ref{eq:ex1} can be removed making it $Pr(y|x,v_1)$. Expression \ref{eq:ex3} is applying do-rule 3. Again by placing variables from this model the condition is holding as $(X\indep V_{1})_{\g_{\overline{X}}}$ and enables the modification suggested by rule 3 to be applied for last part of expression \ref{eq:ex3} so it can be wrote as $Pr(v_{1})$.

This expression would now enable evaluation of causal effect since it does not contain do-operators anymore. With do-calculus it would be even possible with observational data. CI with observational is somewhat controversial topic on which Pearl is strong advocate of it (\cite{Pearl2018}). Despite that, Imbens writes economists are many times believing randomized controlled trials to be more convincing. Or alternatively if doing inference with observational data using research design modeled as such, like regression discontinuity design, and taking advantage of situations where randomization is true for at least subpopulation of sample (\cite{imbes2020}). Problem with these methods is that these does not have such clear graph representation as Imbens points out.

In addition to Pearl's model there exists also other approaches, most significantly in context of economics system developed by economist James Heckman and Rodrigo Pinto (\cite{Heckman2015}). Their model uses approach, derived from Haavelmo's work regarding CI (\cite{Haavelmo1943}; \cite{Haavelmo1944}) and applied to graphs. Heckman's model is using, in addition to the empiric model common to both model, hypothetical model shown in figure \ref{fig:do example}. Difference in the hypothetical version is the added variable $\tilde X$ that does not have any incoming edges but all the arrows that were emerging from $X$ are now emerging from $\tilde X$. This new variable contains the values for which the causal effect is assessed. This differentiates models as Pearl's version is manipulating empirical model with do-calculus (\ref{list:do}) and Heckman is considering entirely different graph for estimation that has one more node. Benefit from this is that in hypothetical model no other tool, such as do-calculus is needed, and model can be estimated with basic probability theory.

Heckman's model is making some of the identification tasks easier of which the IV-identification is probably most important to economics. Identifying IV is not possible in basic form of Pearl's framework. Even though This approach has some desirable features there does not exist much literature around this version on model. As far as I am aware there neither exist any empirical research using this model. For that reason, focus will be in Pearl's approach.

With tools provided in this section we can now understand the basics of identifying causal effects in graphs as well as start to see some flaws and benefits for specific applications. Something more to mention, connected to these methods is that since graphical CI methods have largely been developed by computer scientist, there exists rather efficient algorithms to execute each method introduced above in practice making those quite nice and easy to use, of course still bounded with the normal restrictions for algorithmic efficiency related to graphs.

\clearpage

\section{Applications and properties of DAG framework in context of econometric analysis} \label{section:economics}

This part of thesis will first go through some research papers wrote in economics using DAGs. This literature is not very broad and those papers that are written using this framework are only using it to find out correlation structures of time series data with Granger causality and not using causal identification methods.

After this, some theoretical problems that are preventing the use for applications like applied micro econometric where those features that really make it useful in other fields like do-calculus could be used. Here restrictions of functional form and structure appear as big obstacles to work out to have possibilities for wider use in econometrics.

Lastly there is section going through benefits of DAGs for economic applications. This section will take a bit closer look at some of the topics already touched before like easy execution of identification. In additions some new features for framework, like transportability are introduced and some possibilities with these are discussed.

\subsection{Existing applications of DAGs in economic literature}

Existing empirical economic literature using DAGs at least in some form is mostly concentrated around time series data and modeling phenomenon like price drivers or contagion and transmission channels in international trade and financial applications. These papers are establishing Granger causality in chosen model (\cite{Awokuse2003}; \cite{Bessler2003}; \cite{Yang2006}). There are also some more recently published articles covering topics such as natural gas price drivers (\cite{Ji2018}), this also use similar model to those in older papers. The above-mentioned papers are using DAGs in very similar manner with similar techniques as introduced in sections \ref{subsection:d and indep} and \ref{subsection:stat}. As these are establishing Granger causality with time series macro data, identification methods are not used due to these graphs not being causally sufficient.

\input{empiric_example}

From methodological viewpoint, and especially DAG viewpoint these articles are all using quite similar methods and I have picked one of those that represents well this literature to go through more thoroughly. Yang's article is using VAR error correction model (ECM) on which it is applying DAG. ECM is model used for cointegrated time series, and in this case unit root of CPI is tested by the Johansen's trace test (\cite{Johansen1991}) and deemed significance. ECM enables more precise analysis of cointegration structure and dynamics between short- and long-term effects differentiating it from normal VAR model (\cite{lütkepohl_krätzig_2004}). With results of this model Yang et al. calculates forecast error in this model and uses covariance decomposition of that as input for DAG. Other articles mentioned are having setups very close to or even identical to this and applying it to data considering their research question.

DAG part in each of the papers are executing PC-algorithm (\cite{Spirtes2000}) which is identifying the statistically significant edges in graph. In principle it works by testing whether, for each $V_{i}\in\vars$ independence $V_{i}\indep V_{j}$ where $V_{j}\in\{\pa{V_{i}}\cup\ch{V_{i}}\}$
when $i\neq j$ and $V_{i},V_{j}\in\g$ with chosen statistical test holds, in this case Fischer's z-statistic. If $V_{i}\indep V_{j}$ holds significantly then algorithm proceeds to removing the edge between them. Then it goes on with the same setup, but adding conditioned variables one by one as $V_{i}\indep V_{j}|\{V_{1},V_{2},\ldots,V_{n}\}$ when $V_{1},V_{2},\ldots,V_{n}\in\{\vars\setminus\{\{V_{i}\}\cup\pa{V_{i}}\cup\ch{V_{i}}\}\}$ and deleting edges if this holds statistically significantly. After the information of independence is stored, it is possible to deduce directions edges. In this case PC-algorithm can identify all edges with $p=5\%$ but this is not necessarily the case and there might be multiple graphs in some Markov equivalent class. Markov equivalence class is set of graphs with same independence relations. In this particular case all of the directions are found out and Markovian class is singleton containing only graph shown in figure \ref{fig:empiric}.

%This class contains all of the possible directed graphs that could be fitted to remaining undirected edges, i.e. each undirected edge can be $\rightarrow$, $\leftarrow$ or $\leftrightarrow$ so Markovian class includes all different combinations of these for the part of undirected edges. In this particular case all of the directions are found out and Markovian class is singleton containing only graph shown in figure \ref{fig:empiric}.

Articles discussed here are all operating with macro level data establishing Granger causality. Even though the name is suggesting causality, it is more of a hypothesis test on whether some time series is useful for forecasting other. Writers also acknowledge the possibility this is not complete graph of this process. Causal sufficiency which requires the graph to be complete description of variables affecting phenomena is an assumption that needs to be satisfied to interpret graph as causal. If graph is not sufficient for causal interpretation it is not possible to calculate any causal effects either. Thus, none of the articles is applying identification methods to calculate that. This is not really the type of use cases Pearl or Heckman and Imbes are talking in their text, as they are paying more attention to causal identification.

There does not seem to be applied microeconometric papers using DAGs while those would be the type of research that could use identification methods. These studies, using only PC-algorithm are using DAGs for econometrics but not really doing the causal inference part all the way through. To do the causal inference part they would need to further try to find effect of some variable to other and estimate it, which in this setup would not be possible or at least credibility of those estimates would be questionable as these graphs are not fulfilling the causal completeness.

\begin{comment}
So strong representation of time series econometrics in association with DAGs is somewhat surprising considering that time series models are not so much featured in theoretical DAG literature and for parts it is, it tends to be about questions not really applicable in econometrics. Interest of theoretical literary is more focused around data where time discretion is less problem on data generation level. Those models also trying to establish "instantaneous" or "contemporaneous" relation which are faster than the measurement and differing from the models measuring the transition against the time change of variable or Granger causality that are used in economics (\cite{Hyttinen2017}). Also the Granger causality is somewhat problematic as a name for this method as it is not really a causal connection but rather just test of hypothesis with implications of such, rather than causality.

Already mentioned paper of Ji, Zhang and Geng (\cite{Ji2018}) is also example of something where economic researchers have found some use for DAGs. Article considers gas prices but more generally in energy economics there exists some papers like paper from Yang and Zhao \textit{Energy consumption, carbon emissions, and economic growth in India: Evidence from directed acyclic graphs} (\cite{Yang2014}). This paper considers, rather than price information time series data of emissions, energy consumption, capital formation, trade openness and GDP. The basic setup of article is otherwise very similar to other aforementioned articles and the idea is to find the transmission paths that are affecting energy consumption. In this article researchers are also able to find significant Granger causalities between variables like openness of economy, income, maybe a bit less surprisingly energy consumption and pollution but still these are not very good examples of graphical causal model.

For other parts the only thing these articles are taking from DAG framework is the basic structure and way to present the structure which is completely comprehensible with the knowledge provided in the section \ref{section:overview} and equation \ref{eq:lmc}. Also the fact that these are only establishing Granger causality between variables, so analysis is just concentrated on correlations and thus none provides any economic usage of the identification tools that are associated with graphs nor any use for do-calculus. Also as it is not intended to measure actual causality these graphs could not fulfill the completeness requirement of CI in graphs. As an example the Selma Jaytech's paper is only using prince information of stocks and bonds from different countries as determining variables for other countries price variables. It of course could not be adequate model to make complete graph as the international asset markets are not some fully endogenous self defining system, but rather there is some exogenous factors that affecting the movements. All of this might very well be sufficient for the purpose of the study, but at the same time it is making these studies, from the standpoint of graphical models and CI, not that great of an examples for the use of theoretical framework of DAG CI in economics. In other words these papers are using DAGs just as a way to present models visually and the PC algorithm as statistical test for the direction of flow of correlations in time, which makes the model kind of truncated and leaves lot on table for the part of DAG CI. Methods here use the DAG methods only for finding out the structure but not identifying the causality, since this setup is only able to measure Granger causality.
\end{comment}


\subsection{Theoretical problems for economic applications}\label{subsection:problems}

There is not any one thing preventing the use of DAGs in econometric analysis. Neither do I believe that Imbens on his text about \textit{The Book of Why} (\cite{PearlMackenzie18}) or Heckman (\cite{Heckman2015}) are, despite quite critical view of models fit for econometric use, to say that there would not be any use cases for it in economic literature. However, DAGs still contain some inconveniences or assumption not that well applicable to economics which will be discussed next.

Some of the problems of DAGs are more technical in nature and others more of a question of taste and acquired habits, like which framework one thinks is clearer on its notation's, potential outcomes or DAGs. I will first look on the more technical side of these problems and discuss where DAG approach falls short of techniques used for econometrics. After that some of conceptual or otherwise inconvenient properties will be revised. It should also be noted that DAGs or at least the formal notations of do-calculus are relatively new techniques and the research regarding those is very active so some of the problems mentioned here might not remain unsolved for very long as the research proceeds.

One very clear lack in DAGs is that those cannot identify nonparametric IV-setup with methods introduced before. This is outcome of the fact that graphs are usually used as nonparametric models and the functional form of phenomena modeled is unknown from the beginning. The fact that the functions are not restricted can, and especially Pearl would in general argue to be good thing and add flexibility to the model. However, in IV setup this can cause some additional headache as it also leads to it not having as straight forward way to set shape restrictions for functions, like monotonicity in this case as Imbens points out (\cite{imbes2020}). There exists workarounds and other solutions like getting bounds for average causal effect which is possible in nonparametric setting (\cite{Balke1997}). There is also active research considering techniques for identifying instrumental variables in graphs as well as other identifying methods in nonparametric settings (\cite{Freyberger2017}; \cite{Freyberger2015}). One very recent working paper (\cite{Hoveid2021}) which show a way to identify IV, but this is applicable only under linearity. Also Pearl has noted about IV, that if variable in question can be reasoned to really be exogenous DAG might not be the right tool for the job (\cite{PearlMackenzie18}). Lack of easy way for IV is said to be one of the big reason why DAGs are not adopted to economics by Imbes and Heckman (\cite{Imbens2014}; \cite{imbes2020}; \cite{Heckman2015}) and they are spending quite large amount of the analyses talking about that and the function restrictions.

This problem also extends further than instrumental variables as in economics shape restricted functions are commonly used to bring some already known properties into model. Other occasions for restrictions might be even more bounding as it is common for those restrictions to be consequence of economic theory. This situation might arise for example while defining production function which may be desired to be monotonically increasing but with a diminishing return to scale such as Cobb-Douglas function. Economic theory is playing important role as substantive knowledge of underlying causal structure. After all causal claims need to be based on something more than just statistical relationship --- making PC-algorithm imperfect way to gain knowledge about causality. Any correlation-based method cannot gain certain knowledge about causality, as correlation by itself does not imply causality and vice versa lack of correlation does not necessarily imply lack of causality.

\begin{comment}
Economic theory being the factor that is in a way differing it from other kind of more general statistics inclined towards social phenomenons and the framework through which it is possible to even study the causal structures as those need the substantive knowledge of topic to have even possibility to be interpreted as CI at all. 
\end{comment}

\input{equilibrium}

Another phenomenon not easily represented in DAG is equilibrium condition, unfortunately something quite crucial in economics. This is immediate result of the definition as acyclic. Equilibrium is clearly resulting to cycle in graph as in figure \ref{fig:equilibrium}, showing simple equilibrium condition. Equilibrium introduces feedback mechanism between, for example price and quantity constructing the cycle. This is also noted in other disciplines as well, and thus also this is something under very active research. There has already been some research on cyclic graphs that have been able to prove linear-SEM leading to global Markov property, which is generalization from local Markov property extended to cover, in addition to variables also subsets of variables in directed graph (\cite{PeterSpirtes1994}).

Some of the most recent, and quite ambitious try in a sense that it has tried to solve both problems of cyclical components in graphs and latent confounders, are made by Forré and Mooij (\cite{Forre2017}; \cite{Forre2018}; \cite{Forre2019}). This approach retains the Markovian properties for graph and enables non-linear functional forms. Forré and Mooij are proposing two different models that they are calling modular-SEM (mSEM) and more recent conditioned version of that input/output-SEM (ioSEM). These would take care at least some of those problems although with the cost of making the model notably more complicated. Basic idea for both models is to generalize methods that were presented before by introducing these new class of graphs like hyperedged\footnote{Hyperedged graph or hypergraph is more general type of graph allowing edges to connect multiple nodes.} directed graphs. Forré and Mooij are able to generalise methods like d-separation used in normal DAG to what they call $\sigma$-separation (\cite{Forre2017}) which is having same effect for these types of graphs but which can be considered as extension of d-separation as it reduces to effectively same method as d-separation when applied to DAG. By doing these changes Forré and Mooij are able to generalize the separation algorithm providing representation for conditional independencies in a model which includes cycles as well as conditions for applying mSEM with the graphs (\cite{Forre2017}; \cite{Forre2018}). And then make even further modification to rules so that any distributions and nonlinear functional forms are applicable as well as generalized versions of identifying algorithms (back door (\ref{eq:bd}), front door (\ref{eq:fd}), \& $zID$-methods) as well as generalized version of do-calculus (\ref{list:do}) (\cite{Forre2019}) although it should be noted that this work is partly still at the working paper stage rather than fully published. This kind of modified models, if those can be well implemented, could make a big difference for economic applicability as it would allow modeling equilibrium and enable using these in wider range of causal questions.

\subsection{Advantages and possibilities of graphical models in econometrics} \label{subsection:benefits}

Despite the negative aspects, graphs hold potential for future and some already existing benefits for CI. Among those are easy visualization and estimation as well as some of the more technical properties like formalized way to combine or move models. This section will take deeper look at these.

Economic papers are usually not written just to be read by other economists and CI is many times done in settings which also have policy implications. Especially in those cases it might be beneficial to be able to present models and variables with their connections as simply as possible. For this DAGs are very clean and intuitive way. However, this comes with the cost of being very simplified version of what is happening so argument also goes other ways around and someone with lots of knowledge with statistical methods might find algebraic expressions more explicit and precise way to communicate models as Imbens notes (\cite{imbes2020}).

DAGs could also be used to find appropriate controls for the estimated model. Cunningham in his book (\cite{Cunningham2021}) is making the remark that as table \ref{tab:independence} shows when nodes are forming collider, conditioning it can open path causing dependency between variables. This would cause bias to model. To perceive the colliders DAGs are very good  framework to think of as they show the concept of path in much more evident way compared to regression function. Example of this can be seen in figure \ref{fig:topological} where colliders are easy to see from graph ($V_{4}$ and $V_{5}$) but even easier from the topological order where all nodes with more than one incoming edge are colliders. This is also one of the areas which is under active research and for example this very recent working paper by Hünermund and his coauthors (\cite{Hunermund2021}) are considering choosing controls for model with micro level data. This, still very early-stage paper, is developing system by which these bad controls could be systematically assessed. In addition to developing system and using it with simulated data they are using this for empiric data from paper by Blau and Kahn (\cite{Blau2017}) about gender wage gap. Hünermund et al. are testing the effect of controlling marital status to model, which is thought to be bad control due to endogeneity with women's decision to join labor-force. They are getting fairly similar results between their model when their model is including broader set of controls and OLS but finding out that the inclusion of marital status to widen the pay gap between models by 10.6\% and concluding that choosing controls can significantly change the implications of study.

When estimating model with DAGs this clarity also extends to the estimation. Proving very complicated structural model with many variables can quickly get very complex. In DAGs proving is quite easy to show with identification methods. Many of the identification methods also have complete algorithms that can do the job, like the algorithm to find efficient sets for back door criteria (\ref{eq:bd}) (\cite{Correa2017}). This saves the user of model from doing the more technical work and instead lets researcher to focus improving the causal structure and interpreting results. In general estimating models in this framework is quite easy as most of the new features are also developed with algorithmic solution from the beginning.

Another nice property of causal connections that are found in DAGs arise from the feature introduced as problem before but can also be beneficial in some cases. Very little restrictions for functional form in DAG, the exact problem causing pain with IVs lead also to those causal observations having very little restrictions in functional sense and thus holding with very little restrictive assumptions making it quite robust in that sense as Heckman points out (\cite{Heckman2015}). However, for economics this property is somewhat of a two-edged sword as it makes introducing other restriction in DAG model that might arise from economic theory.

One repeatedly occurring problem in economics is selection bias and for that there already exists machinery in DAG-literature that works without restricting the functional form that can be applied in model (\cite{Bareinboim2014}). Selection node can be introduced to normal DAG and with help of that it is possible to expands the use of model for biased samples and use it with hybrid sources where part of the estimates might be done with unbiased data and other with biased. This kind of situation might arise when some of the estimators that are necessary for the identification might be more easily available e.g., from some statistical authority, but other part would require using more unbalanced data. This could have potentially many applications and might reduce costs of doing research in this kind of situations. Example of such situation might be to help political decision making when question can be modeled as causal question, but relations have been very hard to establish or doing that would have been too expensive.

Selection nodes can also help make studies more externally valid or "transportable" as it is called in computer science literature (\cite{Pearl2011}). Term transportability is not exact synonym to external validity but applying same model to new place by changing some part of that with the technique established by Pearl (\cite{Pearl2011}). Conditions under which transportation can be applied are formally defined (\cite{Bareinboim2012a}). Term external validity is already used in some instances and in my opinion, even though not perfect, quite good to capture essence of the concept. Transportability is in a sense extension of selection nodes and in this case selection nodes are introduced to other parts of model where those are adding information about other domains of model that are some ways altered when model is used in other than its original location.

Third concept related to selection and transporability is meta-synthesis which enables integrating information from multiple models to one and thus estimating effects, with background information of the specific setup but with models originally empirically estimated somewhere else (\cite{Pearl2012a}). Meta-synthesis would enable a bit similar situation as transportability but rather than moving whole model, building a new one from pieces of multiple models. This could also benefit economic research on similar kind of situations as transportability as it might enable easier data gathering processes to areas where data is sparse or somehow hard to acquire.

These features could be divided to two different categories that might be described as the benefits of the conceptual framework and benefits that arise from the technical possibilities, concentrated around the selection nodes. In short the first category would contain the nice and understandable representation of model and the way through which other variables can be seen within that enabling bit different perspective for control variables. Second category adds selection bias recovery, transportability, and meta-synthesis to the toolkit of economist. These can help estimating model in places where data is sparse, it is other ways hard or impossible to get or just lower the cost of it when it might be too costly to estimate otherwise.

\begin{comment}
\hl{These} would enable using once done model in some place that must have same causal structure, but there might be some factors affecting the estimates differing from the original location to be used also in the second place. This would of course be again highly useful for economics and as selection recovery this might make implementing models for different settings much cheaper and thus also possible in smaller settings which might enable better policy recommendation and better decision making for smaller units such as municipalities. Also some complicated questions like how the social security system should be renewed in could be assessed more carefully with perhaps some research done in fairly similar setting in other country. Even thought this seems very promising and usable this is of course no silver bullet solving every problem. Even though there might be interesting use cases this requires the causal structure being exactly same to retain the causal interpretation and exactly same causal structures are of course in real world very hard to find.
\end{comment}

\clearpage

\section{Conclusion}

DAGs are already seeing lot of applications in areas such as epidemiology but have not been as popular in economics. So, what is the reasons for economists not to choose this approach for CI? I think this can be divided to roughly four categories that vary on how easy those are solve as well as on the nature of problem. First one is simply because it is quite new and have not been used in many existing studies. In other words, there is not that much economic research done with it which raises the bar for using it in new projects.

Second category contains technical questions, like functions shape restrictions. This is of course also partly guilty for the first one as it is one of the reasons that prevents use in some cases. However, for these problems there might be some solutions on a way or at least there are many people trying to come up with those as was discussed in section \ref{subsection:problems}. Another technical problem is considering the trouble DAGs are having with the cyclicity as the name already suggests. This is making it more irrelevant and preventing the use of DAGs in econometric applications as many of those are considering some situation with equilibrium condition. Even though Pearl have tried to show this could be solved with fairly simple solution (\cite{PearlMackenzie18}) for Imbens and Heckman this has not been (\cite{imbes2020}; \cite{Heckman2015}) sufficient solution since Pearls proposal is more or less just ignoring the equilibrium condition by making demand affect supply directly instead of through price.

Last of these general categories I identified is connected with the way graphs are done and thought. As this approach is arising from computer science departments more than from economics departments in its modern form, it also contains some of the drawbacks and benefits discipline is able to provide. One of such, that is in principle a good thing is the ways in which identification is done. It is possible to save the essence of these methods to simple form and develop algorithm to do the job. However, model or graph needs to be done by someone knowing these connections very well to place arrows to right places. Although there is also these machine learning methods in development, that are trying to do the identification automatically there must be some substantive knowledge about the situation. After that is done the rest is very mechanical and might feel very alluring to take answers as given even though this is completely conditional to the building the causal structure. This of course is not necessarily bad thing but rather something that needs lot of attention and questioning the assumptions model is making even though it might superficially look alright. There also exists kind of mental asymmetry between adding and \textit{not adding} edge in graph. Even though adding edges is of course important in sense that it builds the model by adding causal relationship, not adding edge is in a way even stronger assumption of the underlying phenomena. By not adding edge person doing the model is saying that variables are absolutely not affecting each other, at least directly, in comparison to adding one might range from effecting just a bit to being the sole deterministic cause. In economics it is very hard to be convinced two events are not in any way connected. One of major mechanisms causing this being such a fundamental part of economics, namely the tendency for economic agents to somehow optimize their behavior in a way that is considering the surrounding environment and potential outcome at given situation. This is making causal structures immensely complicated as the reaction to phenomenon's are dependent of such vast number of factors and full confidence for any given structure is hard to achieve. Not including edge in model could be compared to claiming that the instrument is exogenous in IV model. In DAGs it is not as strict as in some places it might not affect the model but regardless of that model could have bias if only one of the edges is missing so in principle there is $|\vars|^2$ minus added edges of those conditions to argue for. Some of those are also making model cyclical so these would prevent estimating causal effect.

Some of the interesting future research, apart from the theoretical challenges that needs to be solved for DAGs to find more use in economics could be related to the already mentioned (\ref{subsection:benefits}) properties of selection, transportability, and meta-synthesis. Both theoretical question for generalizing results of model by identifying the differing factors in research setting, that have already gained interest of researchers (\cite{Cinelli2021}) and the empirical questions that might get some answers by applying those (\cite{Dahabreh2020}) for transporting randomized controlled trial research to conclude average treatment effects in new target population. These also seems something that could offer lot for economic research and make it more accessible in some situations.

Such questions where these could add value for economic research, and through it to public decision making might be here in Finland questions regarding incoming reforms on social security and health care. Both reforms are allocating some of the responsibilities to provincial and municipal levels. However, it is not attainable to have randomized controlled trials considering all these units of governance due to costs associated. Still it does not seem likely that those would all have homogeneous effects on these reforms. By doing research on more centralized manner and having broad data considering the selection within areas would allow using these models and some local, maybe even already existing registry data to get at least some approximates for the local effects on various questions. This could further extend ability to make informed decisions on lower levels of administration. In application these might enable answering questions like what kind of employment services would benefit each area most given the structure of population and other variables deemed relevant.

%% Opinn\"aytteess\"a jokainen osa alkaa uudelta sivulta, joten \clearpage
%%
%% In a thesis, every section starts a new page, hence \clearpage
\clearpage

\addcontentsline{toc}{section}{References}
\section*{References}
%\printbibliography[
%    heading=bibintoc,
%    title={References},
%    type=none
%]
\printbibliography[
    heading=subbibintoc,
    type=article,
    title={Articles \& seminar papers}
]
\printbibliography[
    heading=subbibintoc,
    type=book,
    title={Books}
]
\printbibliography[
    heading=subbibintoc,
    type=misc,
    title={Other sources}
]

\clearpage

\end{document}